{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T00:30:27.900301Z",
     "start_time": "2018-07-10T00:30:26.138368Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyuvdata import UVData, UVCal\n",
    "from hera_cal import io\n",
    "from pyuvdata.utils import polnum2str, polstr2num, jnum2str, jstr2num\n",
    "from hera_cal.datacontainer import DataContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T00:30:27.905930Z",
     "start_time": "2018-07-10T00:30:27.902192Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "import collections\n",
    "from collections import OrderedDict as odict\n",
    "import copy\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T00:30:27.910608Z",
     "start_time": "2018-07-10T00:30:27.907665Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# new utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T00:30:29.018703Z",
     "start_time": "2018-07-10T00:30:29.012128Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def split_pol(pol):\n",
    "    '''Splits visibility polarization string into anntenna polarizations.'''\n",
    "    if polstr2num(pol) > 0: # this includes Stokes and pseudo-Stokes visibilities \n",
    "        raise ValueError('Unable to split Stokes or pseudo-Stokes polarization ' + pol)\n",
    "    return jnum2str(jstr2num(pol[0])), jnum2str(jstr2num(pol[1]))\n",
    "\n",
    "def conj_pol(pol):\n",
    "    '''Given V_ij^(pol), return the polarization of V_ji^(conj pol) such \n",
    "    (V_ji^(conj pol))* = V_ij^(pol). This means xy -> yx and yx -> xy, but\n",
    "    psuedo-Stokes visibilities are unaffected. Case is left unmodified.'''\n",
    "    if polstr2num(pol) > 0:  # this includes Stokes and pseudo-Stokes visibilities \n",
    "        return pol\n",
    "    else:\n",
    "        return pol[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T00:30:29.237625Z",
     "start_time": "2018-07-10T00:30:29.233243Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# class Test_Pol_Ops(unittest.TestCase):\n",
    "    \n",
    "#     def test_split_pol(self):\n",
    "#         self.assertEqual(split_pol('xx'),('jxx','jxx'))\n",
    "#         self.assertEqual(split_pol('xy'),('jxx','jyy'))        \n",
    "#         self.assertEqual(split_pol('XY'),('jxx','jyy'))\n",
    "#         with self.assertRaises(ValueError):\n",
    "#             split_pol('I')\n",
    "#         with self.assertRaises(ValueError):    \n",
    "#             split_pol('pV')           \n",
    "            \n",
    "#     def test_conj_pol(self):\n",
    "#         self.assertEqual(conj_pol('xx'),'xx')\n",
    "#         self.assertEqual(conj_pol('XX'),'XX')        \n",
    "#         self.assertEqual(conj_pol('XY'),'YX')\n",
    "#         self.assertEqual(conj_pol('yx'),'xy')\n",
    "#         self.assertEqual(conj_pol('Q'),'Q')\n",
    "#         self.assertEqual(conj_pol('pU'),'pU')\n",
    "        \n",
    "# if __name__ == '__main__':\n",
    "#     unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# HERACal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T00:30:29.681854Z",
     "start_time": "2018-07-10T00:30:29.616355Z"
    },
    "code_folding": [],
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "class HERACal(UVCal):\n",
    "    '''HERAData is a subclass of pyuvdata.UVCal meant to serve as an interface between \n",
    "    pyuvdata-readable calfits files and dictionaries (the in-memory format for hera_cal)\n",
    "    that map antennas and polarizations to gains, flags, and qualities. Supports standard\n",
    "    UVCal functionality, along with read() and update() functionality for going back and\n",
    "    forth to dictionaires. Upon read(), stores useful metadata internally.\n",
    "    \n",
    "    Does not support partial data loading or writing. Assumes a single spectral window.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, input_cal):\n",
    "        '''Instantiate a HERACal object. Currently only supports calfits files.\n",
    "        \n",
    "        Arguments:\n",
    "            input_cal: string calfits file path or list of paths\n",
    "        '''\n",
    "        super(HERACal, self).__init__()\n",
    "        \n",
    "        # parse input_data as filepath(s)\n",
    "        if isinstance(input_cal, str):\n",
    "            self.filepaths = [input_cal]\n",
    "        elif isinstance(input_cal, collections.Iterable):  # List loading\n",
    "            if np.all([isinstance(i, str) for i in input_cal]):  # List of visibility data paths\n",
    "                self.filepaths = list(input_cal)\n",
    "            else:\n",
    "                raise TypeError('If input_cal is a list, it must be a list of strings.')\n",
    "        else: \n",
    "            raise ValueError('input_cal must be a string or a list of strings.')\n",
    "\n",
    "    def _extract_metadata(self):\n",
    "        '''Extract and store useful metadata and array indexing dictionaries.'''\n",
    "        self.freqs = np.unique(self.freq_array)\n",
    "        self.times = np.unique(self.time_array)\n",
    "        self.pols = [jnum2str(j) for j in self.jones_array]\n",
    "        self._jnum_indices = {jnum: i for i, jnum in enumerate(self.jones_array)}        \n",
    "        self.ants= [(ant, pol) for ant in self.ant_array for pol in self.pols]\n",
    "        self._antnum_indices = {ant: i for i, ant in enumerate(self.ant_array)}        \n",
    "        \n",
    "    def build_cal_dicts(self):\n",
    "        '''Turns the calibration information currently loaded into the HERACal object\n",
    "        into dictionaries that map antenna-pol tuples to calibration waterfalls. Computes\n",
    "        and stores internally useful metadata in the process.\n",
    "        \n",
    "        Returns:\n",
    "            gains: dict mapping antenna-pol keys to (Nint, Nfreq) complex gains arrays\n",
    "            flags: dict mapping antenna-pol keys to (Nint, Nfreq) boolean flag arrays\n",
    "            quals: dict mapping antenna-pol keys to (Nint, Nfreq) float qual arrays\n",
    "            total_qual: dict mapping polarization to (Nint, Nfreq) float total quality array\n",
    "        '''\n",
    "        self._extract_metadata()\n",
    "        gains, flags, quals, total_qual = odict(), odict(), odict(), odict()\n",
    "              \n",
    "        # build dict of gains, flags, and quals\n",
    "        for (ant, pol) in self.ants:\n",
    "            i, ip = self._antnum_indices[ant], self._jnum_indices[jstr2num(pol)]\n",
    "            gains[(ant, pol)] = np.array(self.gain_array[i, 0, :, :, ip].T)\n",
    "            flags[(ant, pol)] = np.array(self.flag_array[i, 0, :, :, ip].T)\n",
    "            quals[(ant, pol)] = np.array(self.quality_array[i, 0, :, :, ip].T)\n",
    "        \n",
    "        # build dict of total_qual if available\n",
    "        for pol in self.pols:\n",
    "            ip = self._jnum_indices[jstr2num(pol)]\n",
    "            if self.total_quality_array is not None:\n",
    "                total_qual[pol] = np.array(self.total_quality_array[0, :, :, ip].T)\n",
    "            else:\n",
    "                total_qual = None\n",
    "        \n",
    "        return gains, flags, quals, total_qual\n",
    "\n",
    "    def read(self):\n",
    "        '''Reads calibration information from file, computes useful metadata and returns\n",
    "        dictionaries that map antenna-pol tuples to calibration waterfalls. \n",
    "        \n",
    "        Returns:\n",
    "            gains: dict mapping antenna-pol keys to (Nint, Nfreq) complex gains arrays\n",
    "            flags: dict mapping antenna-pol keys to (Nint, Nfreq) boolean flag arrays\n",
    "            quals: dict mapping antenna-pol keys to (Nint, Nfreq) float qual arrays\n",
    "            total_qual: dict mapping polarization to (Nint, Nfreq) float total quality array\n",
    "        '''\n",
    "        self.read_calfits(self.filepaths)\n",
    "        return self.build_cal_dicts()\n",
    "    \n",
    "    def update(self, gains=None, flags=None, quals=None, total_qual=None):\n",
    "        '''Update internal calibrations arrays (data_array, flag_array, and nsample_array)\n",
    "        using DataContainers (if not left as None) in preparation for writing to disk. \n",
    "\n",
    "        Arguments:\n",
    "            gains: optional dict mapping antenna-pol to complex gains arrays\n",
    "            flags: optional dict mapping antenna-pol to boolean flag arrays\n",
    "            quals: optional dict mapping antenna-pol to float qual arrays\n",
    "            total_qual: optional dict mapping polarization to float total quality array\n",
    "        '''\n",
    "        # loop over and update gains, flags, and quals\n",
    "        data_arrays = [self.gain_array, self.flag_array, self.quality_array]\n",
    "        for to_update, array in zip([gains, flags, quals], data_arrays):\n",
    "            if to_update is not None:\n",
    "                for (ant, pol) in to_update.keys():\n",
    "                    i, ip = self._antnum_indices[ant], self._jnum_indices[jstr2num(pol)]\n",
    "                    array[i, 0, :, :, ip] = to_update[(ant, pol)].T\n",
    "        \n",
    "        # update total_qual\n",
    "        if total_qual is not None:\n",
    "            for pol in total_qual.keys():\n",
    "                ip = self._jnum_indices[jstr2num(pol)]\n",
    "                self.total_quality_array[0, :, :, ip] = total_qual[pol].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T00:30:29.829615Z",
     "start_time": "2018-07-10T00:30:29.817034Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 0 tests in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# from hera_cal.data import DATA_PATH\n",
    "# import os\n",
    "\n",
    "# class Test_HERACal(unittest.TestCase):\n",
    "    \n",
    "#     def setUp(self):\n",
    "#         self.fname_xx = os.path.join(DATA_PATH, \"test_input/zen.2457698.40355.xx.HH.uvc.omni.calfits\")\n",
    "#         self.fname_yy = os.path.join(DATA_PATH, \"test_input/zen.2457698.40355.yy.HH.uvc.omni.calfits\")\n",
    "#         self.fname_both = os.path.join(DATA_PATH, \"test_input/zen.2457698.40355.HH.uvcA.omni.calfits\")\n",
    "    \n",
    "#     def test_init(self):\n",
    "#         hc = HERACal(self.fname_xx)\n",
    "#         self.assertEqual(hc.filepaths, [self.fname_xx])\n",
    "#         hc = HERACal([self.fname_xx, self.fname_yy])\n",
    "#         self.assertEqual(hc.filepaths, [self.fname_xx, self.fname_yy])\n",
    "#         hc = HERACal((self.fname_xx, self.fname_yy))\n",
    "#         self.assertEqual(hc.filepaths, [self.fname_xx, self.fname_yy])        \n",
    "#         with self.assertRaises(TypeError):\n",
    "#             hc = HERACal([0,1])\n",
    "#         with self.assertRaises(ValueError):\n",
    "#             hc = HERACal(None)\n",
    "            \n",
    "#     def test_read(self):\n",
    "#         # test one file with both polarizations and a non-None total quality array\n",
    "#         hc = HERACal(self.fname_both)\n",
    "#         gains, flags, quals, total_qual = hc.read()\n",
    "#         uvc = UVCal()\n",
    "#         uvc.read_calfits(self.fname_both)\n",
    "#         np.testing.assert_array_equal(uvc.gain_array[0, 0, :, :, 0].T, gains[9, 'jxx'])\n",
    "#         np.testing.assert_array_equal(uvc.flag_array[0, 0, :, :, 0].T, flags[9, 'jxx'])        \n",
    "#         np.testing.assert_array_equal(uvc.quality_array[0, 0, :, :, 0].T, quals[9, 'jxx'])                \n",
    "#         np.testing.assert_array_equal(uvc.total_quality_array[0, :, :, 0].T, total_qual['jxx'])\n",
    "#         np.testing.assert_array_equal(np.unique(uvc.freq_array), hc.freqs)\n",
    "#         np.testing.assert_array_equal(np.unique(uvc.time_array), hc.times)        \n",
    "#         self.assertEqual(hc.pols, ['jxx', 'jyy'])\n",
    "#         self.assertEqual(set([ant[0] for ant in hc.ants]), set(uvc.ant_array))\n",
    "        \n",
    "#         # test list loading\n",
    "#         hc = HERACal([self.fname_xx, self.fname_yy])\n",
    "#         gains, flags, quals, total_qual = hc.read()\n",
    "#         self.assertEqual(len(gains.keys()), 36)\n",
    "#         self.assertEqual(len(flags.keys()), 36)\n",
    "#         self.assertEqual(len(quals.keys()), 36)\n",
    "#         self.assertEqual(hc.freqs.shape, (1024,))\n",
    "#         self.assertEqual(hc.times.shape, (3,))\n",
    "#         self.assertEqual(sorted(hc.pols), ['jxx', 'jyy'])\n",
    "        \n",
    "#     def test_write(self):\n",
    "#         hc = HERACal(self.fname_both)\n",
    "#         gains, flags, quals, total_qual = hc.read()\n",
    "#         for key in gains.keys():\n",
    "#             gains[key] *= 2.0 + 1.0j\n",
    "#             flags[key] = np.logical_not(flags[key])\n",
    "#             quals[key] *= 2.0\n",
    "#         for key in total_qual.keys():\n",
    "#             total_qual[key] *= 2\n",
    "#         hc.update(gains=gains, flags=flags, quals=quals, total_qual=total_qual)\n",
    "#         hc.write_calfits('test.calfits', clobber=True)\n",
    "        \n",
    "#         gains_in, flags_in, quals_in, total_qual_in = hc.read()\n",
    "#         hc2 = HERACal('test.calfits')\n",
    "#         gains_out, flags_out, quals_out, total_qual_out = hc2.read()\n",
    "#         for key in gains_in.keys():\n",
    "#             np.testing.assert_array_equal(gains_in[key] * (2.0 + 1.0j), gains_out[key])\n",
    "#             np.testing.assert_array_equal(np.logical_not(flags_in[key]), flags_out[key])            \n",
    "#             np.testing.assert_array_equal(quals_in[key] * (2.0), quals_out[key])\n",
    "#         for key in total_qual.keys():\n",
    "#             np.testing.assert_array_equal(total_qual_in[key] * (2.0), total_qual_out[key])        \n",
    "        \n",
    "#         os.remove('test.calfits')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# HERAData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T01:25:09.078956Z",
     "start_time": "2018-07-10T01:25:08.437033Z"
    },
    "code_folding": [
     105,
     121
    ],
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "class HERAData(UVData):\n",
    "    '''HERAData is a subclass of pyuvdata.UVData meant to serve as an interface between \n",
    "    pyuvdata-compatible data formats on disk (especially uvh5) and DataContainers,\n",
    "    the in-memory format for visibilities used in hera_cal. In addition to standard \n",
    "    UVData functionality, HERAData supports read() and update() functions that interface\n",
    "    between internal UVData data storage and DataContainers, which contain visibility\n",
    "    data in a dictionary-like format, along with some useful metadata. read() supports\n",
    "    partial data loading, though only the most useful subset of selection modes from \n",
    "    pyuvdata (and not all modes for all data types).\n",
    "    \n",
    "    When using uvh5, HERAData supports additional useful functionality:\n",
    "    * Upon __init__(), the most useful metadata describing the entire file is loaded into\n",
    "      the object (everything in HERAData_metas; see get_metadata_dict() for details).\n",
    "    * Partial writing using partial_write(), which will initialize a new file with the\n",
    "      same metadata and write to disk using DataContainers by assuming that the user is\n",
    "      writing to the same part of the data as the most recent read().\n",
    "    * Generators that enable iterating over baseline, frequency, or time in chunks (see \n",
    "      iterate_over_bls(), iterate_over_freqs(), and iterate_over_times() for details).\n",
    "      \n",
    "    Assumes a single spectral window. Assumes that data for a given baseline is regularly\n",
    "    spaced in the underlying data_array.\n",
    "    '''\n",
    "    \n",
    "    # static list of useful metadata to calculate and save\n",
    "    HERAData_metas = ['ants', 'antpos', 'freqs', 'times', 'lsts', 'pols', \n",
    "                      'antpairs', 'bls', 'times_by_bl', 'lsts_by_bl']\n",
    "\n",
    "    def __init__(self, input_data, filetype='uvh5'):\n",
    "        '''Instantiate a HERAData object. If the filetype is uvh5, read in and store \n",
    "        useful metadata (see get_metadata_dict()), either as object attributes or, \n",
    "        if input_data is a list, as dictionaries mapping string paths to metadata.\n",
    "        \n",
    "        Arguments:\n",
    "            input_data: string data file path or list of string data file paths\n",
    "            filetype: supports 'uvh5' (defualt), 'miriad', 'uvfits'\n",
    "        '''\n",
    "        # initialize as empty UVData object\n",
    "        super(HERAData, self).__init__()\n",
    "        \n",
    "        # parse input_data as filepath(s)\n",
    "        if isinstance(input_data, str):\n",
    "            self.filepaths = [input_data]\n",
    "        elif isinstance(input_data, collections.Iterable):  # List loading\n",
    "            if np.all([isinstance(i, str) for i in input_data]):  # List of visibility data paths\n",
    "                self.filepaths = list(input_data)\n",
    "            else:\n",
    "                raise TypeError('If input_data is a list, it must be a list of strings.')\n",
    "        else: \n",
    "            raise ValueError('input_data must be a string or a list of strings.')\n",
    "        for f in self.filepaths:\n",
    "            if not os.path.exists(f):\n",
    "                raise IOError('Cannot find file ' + f)\n",
    "        \n",
    "        # load metadata from file\n",
    "        self.filetype = filetype        \n",
    "        if self.filetype is 'uvh5':\n",
    "            # read all UVData metadata from first file\n",
    "            temp_paths = copy.deepcopy(self.filepaths)\n",
    "            self.filepaths = self.filepaths[0]\n",
    "            self.read(read_data=False)\n",
    "            self.filepaths = temp_paths\n",
    "            \n",
    "            if len(self.filepaths) > 1:  # save HERAData_metas in dicts\n",
    "                for meta in self.HERAData_metas:\n",
    "                    setattr(self, meta, {})\n",
    "                for path in self.filepaths:\n",
    "                    hc = HERAData(path, filetype='uvh5')\n",
    "                    meta_dict = self.get_metadata_dict()\n",
    "                    for meta in self.HERAData_metas:\n",
    "                        getattr(self, meta)[path] = meta_dict[meta]\n",
    "            else:  # save HERAData_metas as attributes\n",
    "                self.writers = {}\n",
    "                for key, value in self.get_metadata_dict().items():\n",
    "                    setattr(self, key, value)\n",
    "                \n",
    "        elif self.filetype in ['miriad', 'uvfits']:\n",
    "            for meta in self.HERAData_metas:\n",
    "                setattr(self, meta, None)  # no pre-loading of metadata\n",
    "        else:\n",
    "            raise NotImplementedError('Filetype ' + self.filetype + ' has not been implemented.')\n",
    "    \n",
    "    def clear(self):\n",
    "        '''Resets all standard UVData attributes.'''\n",
    "        super(HERAData, self).__init__()\n",
    "    \n",
    "    def get_metadata_dict(self):\n",
    "        ''' Produces a dictionary of the most useful metadata. Used as object\n",
    "        attributes and as metadata to store in DataContainers.\n",
    "        \n",
    "        Returns:\n",
    "            metadata_dict: dictionary of all items in self.HERAData_metas\n",
    "        '''\n",
    "        antpos, ants = self.get_ENU_antpos()\n",
    "        ants = sorted(ants)\n",
    "        antpos = dict(zip(ants, antpos))\n",
    "        \n",
    "        freqs = np.unique(self.freq_array)\n",
    "        times = np.unique(self.time_array)\n",
    "        lst_indices = np.unique(self.lst_array.ravel(), return_index=True)[1]\n",
    "        lsts = self.lst_array.ravel()[np.sort(lst_indices)]\n",
    "        pols = [polnum2str(polnum) for polnum in self.polarization_array]\n",
    "        antpairs = self.get_antpairs()\n",
    "        bls = [antpair + (pol,) for antpair in antpairs for pol in pols]\n",
    "        \n",
    "        times_by_bl = {antpair: np.array(self.time_array[self._blt_slices[antpair]]) \n",
    "                                          for antpair in antpairs}\n",
    "        lsts_by_bl = {antpair: np.array(self.lst_array[self._blt_slices[antpair]]) \n",
    "                                         for antpair in antpairs}\n",
    "\n",
    "        locs = locals()\n",
    "        return {meta: eval(meta, {}, locs) for meta in self.HERAData_metas}\n",
    "\n",
    "    def _determine_blt_slicing(self):\n",
    "        '''Determine the mapping between antenna pairs and\n",
    "        slices of the blt axis of the data_array.'''\n",
    "        self._blt_slices = {}\n",
    "        for ant1, ant2 in self.get_antpairs():\n",
    "            indices = self.antpair2ind(ant1, ant2)\n",
    "            if len(indices) == 1:\n",
    "                self._blt_slices[(ant1, ant2)] = slice(indices[0], indices[0] + 1, self.Nblts)\n",
    "            elif not (len(set(np.ediff1d(indices))) == 1):\n",
    "                raise NotImplementedError('UVData objects with non-regular spacing of ' +\n",
    "                                          'baselines in its baseline-times are not supported.')\n",
    "            else:\n",
    "                self._blt_slices[(ant1, ant2)] = slice(indices[0], indices[-1] + 1, \n",
    "                                                       indices[1] - indices[0])\n",
    "\n",
    "            \n",
    "    def _determine_pol_indexing(self):\n",
    "        '''Determine the mapping between polnums and indices\n",
    "        in the polarization axis of the data_array.'''\n",
    "        self._polnum_indices = {}\n",
    "        for i, polnum in enumerate(self.polarization_array):\n",
    "            self._polnum_indices[polnum] = i   \n",
    "\n",
    "            \n",
    "    def _get_slice(self, data_array, key):\n",
    "        '''Return a copy of the Nint by Nfreq waterfall or waterfalls for a given key. Abstracts \n",
    "        away both baseline ordering (by applying complex conjugation) and polarization capitalization.\n",
    "        \n",
    "        Arguments:\n",
    "            data_array: numpy array of shape (Nblts, 1, Nfreq, Npol) \n",
    "            key: if of the form (0,1,'xx'), return anumpy array.\n",
    "                 if of the form (0,1), return a dict mapping pol strings to waterfalls.\n",
    "                 if of of the form 'xx', return a dict mapping ant-pair tuples to waterfalls.\n",
    "        '''        \n",
    "        if isinstance(key, tuple) and len(key) == 3:  # asking for bl-pol\n",
    "            try:\n",
    "                return np.array(np.squeeze(data_array[self._blt_slices[key[0:2]], 0, :, \n",
    "                                self._polnum_indices[polstr2num(key[2])]]))        \n",
    "            except KeyError:\n",
    "                return np.conj(np.squeeze(data_array[self._blt_slices[key[1::-1]], 0, :, \n",
    "                               self._polnum_indices[polstr2num(conj_pol(key[2]))]]))\n",
    "\n",
    "        elif isinstance(key, tuple) and len(key) == 2:  # asking for antpair\n",
    "            pols = np.array([polnum2str(polnum) for polnum in self.polarization_array])\n",
    "            return {pol: self._get_slice(data_array, key + (pol,)) for pol in pols}\n",
    "        elif isinstance(key, str):  # asking for a pol\n",
    "            return {antpair: self._get_slice(data_array, antpair + (key,)) for antpair in self.get_antpairs()}\n",
    "        else:\n",
    "            raise KeyError('Unrecognized key type for slicing data.')\n",
    "\n",
    "    def _set_slice(self, data_array, key, value):\n",
    "        '''Update data_array with Nint by Nfreq waterfall(s). Abstracts away both baseline \n",
    "        ordering (by applying complex conjugation) and polarization capitalization.\n",
    "        \n",
    "        Arguments:\n",
    "            data_array: numpy array of shape (Nblts, 1, Nfreq, Npol) \n",
    "            key: baseline (e.g. (0,1,'xx)), ant-pair tuple (e.g. (0,1)), or pol str (e.g. 'xx')\n",
    "            value: if key is a baseline, must be an (Nint, Nfreq) numpy array;\n",
    "                   if key is an ant-pair tuple, must be a dict mapping pol strings to waterfalls;\n",
    "                   if key is a pol str, must be a dict mapping ant-pair tuples to waterfalls\n",
    "        '''\n",
    "        if isinstance(key, tuple) and len(key) == 3:  # providing bl-pol\n",
    "            try:\n",
    "                data_array[self._blt_slices[key[0:2]], 0, : , \n",
    "                           self._polnum_indices[polstr2num(key[2])]] = value\n",
    "            except(KeyError):\n",
    "                data_array[self._blt_slices[key[1::-1]], 0, : , \n",
    "                           self._polnum_indices[polstr2num(conj_pol(key[2]))]] = np.conj(value)\n",
    "        elif isinstance(key, tuple) and len(key) == 2:  # providing antpair with all pols\n",
    "            for pol in value.keys():\n",
    "                self._set_slice(data_array, (key + (pol,)), value[pol])\n",
    "        elif isinstance(key, str):  # providing pol with all antpairs\n",
    "            for antpair in value.keys():\n",
    "                self._set_slice(data_array, (antpair + (key,)), value[antpair])\n",
    "        else:\n",
    "            raise KeyError('Unrecognized key type for slicing data.')            \n",
    "     \n",
    "    def build_datacontainers(self):\n",
    "        '''Turns the data currently loaded into the HERAData object into DataContainers.\n",
    "        Returned DataContainers include useful metadata specific to the data actually\n",
    "        in the DataContainers (which may be a subset of the total data). This includes\n",
    "        antenna positions, frequencies, all times, all lsts, and times and lsts by baseline.\n",
    "        \n",
    "        Returns:\n",
    "            data: DataContainer mapping baseline keys to complex visibility waterfalls\n",
    "            flags: DataContainer mapping baseline keys to boolean flag waterfalls\n",
    "            nsamples: DataContainer mapping baseline keys to interger Nsamples waterfalls\n",
    "        '''\n",
    "        # build up DataContainers\n",
    "        data, flags, nsamples = odict(), odict(), odict()\n",
    "        meta = self.get_metadata_dict()\n",
    "        for bl in meta['bls']:\n",
    "            data[bl] = self._get_slice(self.data_array, bl)\n",
    "            flags[bl] = self._get_slice(self.flag_array, bl)\n",
    "            nsamples[bl] = self._get_slice(self.nsample_array, bl)\n",
    "        data = DataContainer(data)\n",
    "        flags = DataContainer(flags)\n",
    "        nsamples = DataContainer(nsamples)\n",
    "        \n",
    "        # store useful metadata inside the DataContainers\n",
    "        for dc in [data, flags, nsamples]:\n",
    "            for attr in ['antpos', 'freqs', 'times', 'lsts', 'times_by_bl', 'lsts_by_bl']:\n",
    "                setattr(dc, attr, meta[attr])\n",
    "            \n",
    "        return data, flags, nsamples\n",
    "    \n",
    "    def read(self, bls=None,  polarizations=None, times=None,\n",
    "             frequencies=None, freq_chans=None, read_data=True):\n",
    "        '''Reads data from file. Supports partial data loading. Default: read all data in file.\n",
    "      \n",
    "        Arguments:\n",
    "            bls: A list of antenna number tuples (e.g. [(0,1), (3,2)]) or a list of\n",
    "                baseline 3-tuples (e.g. [(0,1,'xx'), (2,3,'yy')]) specifying baselines\n",
    "                to keep in the object. For length-2 tuples, the  ordering of the numbers\n",
    "                within the tuple does not matter. For length-3 tuples, the polarization\n",
    "                string is in the order of the two antennas. If length-3 tuples are provided,\n",
    "                the polarizations argument below must be None. Ignored if read_data is False.\n",
    "            polarizations: The polarizations to include when reading data into\n",
    "                the object.  Ignored if read_data is False.\n",
    "            times: The times to include when reading data into the object.\n",
    "                Ignored if read_data is False. Miriad will load then select on this axis.\n",
    "            frequencies: The frequencies to include when reading data. Ignored if read_data \n",
    "                is False. Miriad will load then select on this axis.\n",
    "            freq_chans: The frequency channel numbers to include when reading data. Ignored \n",
    "                if read_data is False. Miriad will load then select on this axis.\n",
    "            read_data: Read in the visibility and flag data. If set to false, only the \n",
    "                basic metadata will be read in and nothing will be returned. Results in an\n",
    "                incompletely defined object (check will not pass). Default True.\n",
    "        \n",
    "        Returns:\n",
    "            data: DataContainer mapping baseline keys to complex visibility waterfalls\n",
    "            flags: DataContainer mapping baseline keys to boolean flag waterfalls\n",
    "            nsamples: DataContainer mapping baseline keys to interger Nsamples waterfalls\n",
    "        '''\n",
    "        # save last read parameters\n",
    "        locs = locals()\n",
    "        partials = ['bls', 'polarizations', 'times', 'frequencies', 'freq_chans']\n",
    "        self.last_read_kwargs = {p: eval(p, {}, locs) for p in partials}\n",
    "        \n",
    "        # load data\n",
    "        if self.filetype is 'uvh5':\n",
    "            self.read_uvh5(self.filepaths, bls=bls, polarizations=polarizations, times=times,\n",
    "                           frequencies=frequencies, freq_chans=freq_chans, read_data=read_data)\n",
    "        else:\n",
    "            if not read_data:\n",
    "                raise NotImplementedError('reading only metadata is not implemented for' + self.filetype)\n",
    "            if self.filetype is 'miriad':\n",
    "                self.read_miriad(self.filepaths, bls=bls, polarizations=polarizations)\n",
    "                if any([times is not None, frequencies is not None, freq_chans is not None]):\n",
    "                    warnings.warn('miriad does not support partial loading for times and frequencies. '\n",
    "                                  'Loading the file first and then performing select.')\n",
    "                self.select(times=times, frequencies=frequencies, freq_chans=freq_chans)\n",
    "            if self.filetype is 'uvfits':\n",
    "                self.read_uvfits(self.filepaths, bls=bls, polarizations=polarizations, \n",
    "                                 times=times, frequencies=frequencies, freq_chans=freq_chans)\n",
    "        \n",
    "        # process data into DataContainers\n",
    "        if read_data or self.filetype is 'uvh5':\n",
    "            self._determine_blt_slicing()\n",
    "            self._determine_pol_indexing()\n",
    "        if read_data:\n",
    "            return self.build_datacontainers()\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        '''Shortcut for reading a single visibility waterfall given a baseline tuple.'''\n",
    "        return self.read(bls=key)[0][key]\n",
    "\n",
    "    def update(self, data=None, flags=None, nsamples=None):\n",
    "        '''Update internal data arrays (data_array, flag_array, and nsample_array)\n",
    "        using DataContainers (if not left as None) in preparation for writing to disk. \n",
    "\n",
    "        Arguments:\n",
    "            data: Optional DataContainer mapping baselines to complex visibility waterfalls\n",
    "            flags: Optional DataContainer mapping baselines to boolean flag waterfalls\n",
    "            nsamples: Optional DataContainer mapping baselines to interger Nsamples waterfalls\n",
    "        '''\n",
    "        if data is not None:\n",
    "            for bl in data.keys():\n",
    "                self._set_slice(self.data_array, bl, data[bl])\n",
    "        if flags is not None:\n",
    "            for bl in flags.keys():\n",
    "                self._set_slice(self.flag_array, bl, flags[bl])\n",
    "        if nsamples is not None:\n",
    "            for bl in nsamples.keys():\n",
    "                self._set_slice(self.nsample_array, bl, nsamples[bl])\n",
    "                \n",
    "    def partial_write(self, output_path, data=None, flags=None, nsamples=None, clobber=False):\n",
    "        '''Writes part of a uvh5 file using DataContainers whose shape matches the most recent\n",
    "        call to HERAData.read() in this object. Does not work for other filetypes or when the\n",
    "        HERAData object is initialized with a list of files. \n",
    "        \n",
    "        Arguments:\n",
    "            output_path: path to file to write uvh5 file to\n",
    "            data: Optional DataContainer mapping baselines to complex visibility waterfalls\n",
    "            flags: Optional DataContainer mapping baselines to boolean flag waterfalls\n",
    "            nsamples: Optional DataContainer mapping baselines to interger Nsamples waterfalls\n",
    "            clobber: if True, overwrites existing file at output_path\n",
    "        '''\n",
    "        # Type verifications\n",
    "        if self.filetype is not 'uvh5':\n",
    "            raise NotImplementedError('Partial writing for filetype ' + self.filetype + ' has not been implemented.')\n",
    "        if len(self.filepaths) > 1:\n",
    "            raise NotImplementedError('Partial writing for list-loaded HERAData objects has not been implemented.')\n",
    "        if not isinstance(output_path, str):\n",
    "            raise ValueError('output_path must be a string path file to write.')\n",
    "        \n",
    "        # get writer or initialize new writer if necessary\n",
    "        if output_path in self.writers:\n",
    "            hd_writer = self.writers[output_path]\n",
    "        else:\n",
    "            hd_writer = HERAData(self.filepaths[0])\n",
    "            hd_writer.initialize_uvh5_file(output_path, clobber=clobber)\n",
    "            self.writers[output_path] = hd_writer\n",
    "        \n",
    "        # make a copy of this object and then update the relevant arrays using DataContainers\n",
    "        this = copy.deepcopy(self)\n",
    "        this.update(data=data, flags=flags, nsamples=nsamples)\n",
    "        hd_writer.write_uvh5_part(output_path, this.data_array, this.flag_array,\n",
    "                                  this.nsample_array, **self.last_read_kwargs)\n",
    "        \n",
    "    def iterate_over_bls(self, Nbls=1, bls=None):\n",
    "        '''Produces a generator that iteratively yields successive calls to \n",
    "        HERAData.read() by baseline or group of baselines.\n",
    "        \n",
    "        Arguments:\n",
    "            Nbls: number of baselines to load at once.\n",
    "            bls: optional user-provided list of baselines to iterate over.\n",
    "                Default: use self.bls (which only works for uvh5).\n",
    "\n",
    "        Yields:\n",
    "            data, flags, nsamples: DataContainers (see HERAData.read() for more info).    \n",
    "        '''\n",
    "        if bls is None:\n",
    "            if self.filetype is not 'uvh5':\n",
    "                raise NotImplementedError('Baseline iteration without explicitly setting bls for filetype ' + self.filetype +\n",
    "                                          '  without setting bls has not been implemented.')\n",
    "            bls = self.bls\n",
    "            if isinstance(bls, dict):  # multiple files\n",
    "                bls = list(set([bl for bls in bls.values() for bl in bls]))\n",
    "            bls = sorted(bls)\n",
    "        for i in range(0, len(bls), Nbls):\n",
    "            yield self.read(bls=bls[i:i + Nbls])\n",
    "\n",
    "            \n",
    "    def iterate_over_freqs(self, Nchans=1, freqs=None):\n",
    "        '''Produces a generator that iteratively yields successive calls to \n",
    "        HERAData.read() by frequency channel or group of contiguous channels.\n",
    "        \n",
    "        Arguments:\n",
    "            Nchans: number of frequencies to load at once. \n",
    "            freqs: optional user-provided list of frequencies to iterate over.\n",
    "                Default: use self.freqs (which only works for uvh5).\n",
    "\n",
    "        Yields:\n",
    "            data, flags, nsamples: DataContainers (see HERAData.read() for more info).    \n",
    "        '''\n",
    "        if freqs is None:          \n",
    "            if self.filetype is not 'uvh5':\n",
    "                raise NotImplementedError('Frequency iteration for filetype ' + self.filetype +\n",
    "                                          '  without setting freqs has not been implemented.')\n",
    "            freqs = self.freqs\n",
    "            if isinstance(self.freqs, dict):  # multiple files\n",
    "                freqs = np.unique(self.freqs.values())\n",
    "        for i in range(0, len(freqs), Nchans):\n",
    "            yield self.read(frequencies=freqs[i:i + Nchans])\n",
    "\n",
    "    def iterate_over_times(self, Nints=1, times=None):\n",
    "        '''Produces a generator that iteratively yields successive calls to \n",
    "        HERAData.read() by time or group of contiguous times.\n",
    "        \n",
    "        Arguments:\n",
    "            Nints: number of integrations to load at once. \n",
    "            times: optional user-provided list of times to iterate over.\n",
    "                Default: use self.times (which only works for uvh5).\n",
    "\n",
    "        Yields:\n",
    "            data, flags, nsamples: DataContainers (see HERAData.read() for more info).\n",
    "        '''\n",
    "        if times is None:\n",
    "            if self.filetype is not 'uvh5':\n",
    "                raise NotImplementedError('Time iteration for filetype ' + self.filetype +\n",
    "                                          '  without setting times has not been implemented.')\n",
    "            times = self.times\n",
    "            if isinstance(times, dict):  # multiple files\n",
    "                times = np.unique(times.values())\n",
    "        for i in range(0, len(times), Nints):\n",
    "            yield self.read(times=times[i:i + Nints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T05:13:55.701019Z",
     "start_time": "2018-07-10T05:13:48.881685Z"
    },
    "code_folding": [
     80,
     104,
     111,
     137,
     163
    ],
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...............\n",
      "----------------------------------------------------------------------\n",
      "Ran 15 tests in 5.460s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "from hera_cal.data import DATA_PATH\n",
    "import os\n",
    "\n",
    "class Test_HERAData(unittest.TestCase):\n",
    "     \n",
    "    def setUp(self):\n",
    "        self.uvh5_1 = os.path.join(DATA_PATH, \"zen.2458116.61019.xx.HH.h5XRS_downselected\")\n",
    "        self.uvh5_2 = os.path.join(DATA_PATH, \"zen.2458116.61765.xx.HH.h5XRS_downselected\")\n",
    "        self.miriad_1 = os.path.join(DATA_PATH, \"zen.2458043.12552.xx.HH.uvORA\")\n",
    "        self.miriad_2 = os.path.join(DATA_PATH, \"zen.2458043.13298.xx.HH.uvORA\")\n",
    "        self.uvfits = os.path.join(DATA_PATH, 'zen.2458043.12552.xx.HH.uvA.vis.uvfits')\n",
    "        self.four_pol = [os.path.join(DATA_PATH, 'zen.2457698.40355.{}.HH.uvcA'.format(pol)) \n",
    "                         for pol in ['xx','yy','xy','yx']]\n",
    "    \n",
    "    def test_init(self):\n",
    "        # single uvh5 file\n",
    "        hd = HERAData(self.uvh5_1)\n",
    "        self.assertEqual(hd.filepaths, [self.uvh5_1])\n",
    "        for meta in hd.HERAData_metas:\n",
    "            self.assertIsNotNone(getattr(hd, meta))\n",
    "        self.assertEqual(len(hd.freqs), 1024)\n",
    "        self.assertEqual(len(hd.bls), 3)\n",
    "        self.assertEqual(len(hd.times), 60)\n",
    "        self.assertEqual(len(hd.lsts), 60)\n",
    "        self.assertEqual(hd.writers, {})\n",
    "        \n",
    "        # multiple uvh5 files\n",
    "        files = [self.uvh5_1, self.uvh5_2]\n",
    "        hd = HERAData(files)\n",
    "        self.assertEqual(hd.filepaths, files)\n",
    "        for meta in hd.HERAData_metas:\n",
    "            self.assertIsNotNone(getattr(hd, meta))\n",
    "        for f in files:\n",
    "            self.assertEqual(len(hd.freqs[f]), 1024)\n",
    "            self.assertEqual(len(hd.bls[f]), 3)\n",
    "            self.assertEqual(len(hd.times[f]), 60)\n",
    "            self.assertEqual(len(hd.lsts[f]), 60)      \n",
    "        self.assertFalse(hasattr(hd, 'writers'))\n",
    "\n",
    "        # miriad\n",
    "        hd = HERAData(self.miriad_1, filetype='miriad')\n",
    "        self.assertEqual(hd.filepaths, [self.miriad_1])\n",
    "        for meta in hd.HERAData_metas:\n",
    "            self.assertIsNone(getattr(hd, meta))\n",
    "\n",
    "        # uvfits\n",
    "        hd = HERAData(self.uvfits, filetype='uvfits')\n",
    "        self.assertEqual(hd.filepaths, [self.uvfits])\n",
    "        for meta in hd.HERAData_metas:\n",
    "            self.assertIsNone(getattr(hd, meta))\n",
    "        \n",
    "        # test errors\n",
    "        with self.assertRaises(TypeError):\n",
    "            hd = HERAData([1,2])\n",
    "        with self.assertRaises(ValueError):\n",
    "            hd = HERAData(None)\n",
    "        with self.assertRaises(NotImplementedError):\n",
    "            hd = HERAData(self.uvh5_1, 'not a real type')\n",
    "        with self.assertRaises(IOError):\n",
    "            hd = HERAData('fake path')\n",
    "\n",
    "    def test_clear(self):\n",
    "        hd = HERAData(self.uvh5_1)\n",
    "        hd.read()\n",
    "        hd.clear()\n",
    "        self.assertIsNone(hd.data_array)\n",
    "        self.assertIsNone(hd.flag_array)\n",
    "        self.assertIsNone(hd.nsample_array)\n",
    "        self.assertEqual(hd.filepaths, [self.uvh5_1])\n",
    "        for meta in hd.HERAData_metas:\n",
    "            self.assertIsNotNone(getattr(hd, meta))\n",
    "        self.assertEqual(len(hd.freqs), 1024)\n",
    "        self.assertEqual(len(hd.bls), 3)\n",
    "        self.assertEqual(len(hd.times), 60)\n",
    "        self.assertEqual(len(hd.lsts), 60)\n",
    "        self.assertEqual(hd.writers, {})\n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "    def test_get_metadata_dict(self):\n",
    "        hd = HERAData(self.uvh5_1)\n",
    "        metas = hd.get_metadata_dict()\n",
    "        for meta in hd.HERAData_metas:\n",
    "            self.assertTrue(meta in metas)\n",
    "        self.assertEqual(len(metas['freqs']), 1024)\n",
    "        self.assertEqual(len(metas['bls']), 3)\n",
    "        self.assertEqual(len(metas['times']), 60)\n",
    "        self.assertEqual(len(metas['lsts']), 60)\n",
    "        np.testing.assert_array_equal(metas['times'], np.unique(list(metas['times_by_bl'].values())))\n",
    "        np.testing.assert_array_equal(metas['lsts'], np.unique(list(metas['lsts_by_bl'].values())))\n",
    "        \n",
    "    def test_determine_blt_slicing(self):\n",
    "        hd = HERAData(self.uvh5_1)\n",
    "        for s in hd._blt_slices.values():\n",
    "            self.assertIsInstance(s, slice)\n",
    "        for bl, s in hd._blt_slices.items():\n",
    "            np.testing.assert_array_equal(np.arange(180)[np.logical_and(hd.ant_1_array == bl[0], \n",
    "                                          hd.ant_2_array == bl[1])], np.arange(180)[s])\n",
    "        # test check for non-regular spacing\n",
    "        hd.ant_1_array = hd.ant_2_array\n",
    "        with self.assertRaises(NotImplementedError):\n",
    "            hd._determine_blt_slicing()\n",
    "    \n",
    "    def test_determine_pol_indexing(self):\n",
    "        hd = HERAData(self.uvh5_1)\n",
    "        self.assertEqual(hd._polnum_indices, {-5:0})\n",
    "        hd = HERAData(self.four_pol, filetype='miriad')\n",
    "        hd.read(bls=[(53,53)])\n",
    "        self.assertEqual(hd._polnum_indices, {-8: 3, -7: 2, -6: 1, -5: 0})\n",
    "        \n",
    "    def test_get_slice(self):\n",
    "        hd = HERAData(self.uvh5_1)\n",
    "        hd.read()\n",
    "        for bl in hd.bls:\n",
    "            np.testing.assert_array_equal(hd._get_slice(hd.data_array, bl), hd.get_data(bl))                                      \n",
    "        np.testing.assert_array_equal(hd._get_slice(hd.data_array, (54, 53, 'XX')),\n",
    "                                      hd.get_data((54, 53, 'XX')))        \n",
    "        np.testing.assert_array_equal(hd._get_slice(hd.data_array, (53, 54))['XX'],\n",
    "                                      hd.get_data((53, 54, 'XX')))\n",
    "        np.testing.assert_array_equal(hd._get_slice(hd.data_array, 'XX')[(53,54)],\n",
    "                                      hd.get_data((53, 54, 'XX')))\n",
    "        with self.assertRaises(KeyError):\n",
    "            hd._get_slice(hd.data_array, None)\n",
    "            \n",
    "        hd = HERAData(self.four_pol, filetype='miriad')\n",
    "        d, f, n = hd.read(bls=[(80, 81)])\n",
    "        for p in d.pols():\n",
    "            np.testing.assert_array_almost_equal(hd._get_slice(hd.data_array, (80, 81, p)),\n",
    "                                                 hd.get_data((80, 81, p)).flatten())\n",
    "            try:\n",
    "                np.testing.assert_array_almost_equal(hd._get_slice(hd.data_array, (81, 80, p)),\n",
    "                                                     hd.get_data((81, 80, p)).flatten())\n",
    "            except: # this is only here until pyuvdata fixes issue #398\n",
    "                np.testing.assert_array_almost_equal(hd._get_slice(hd.data_array, (81, 80, p)),\n",
    "                                                     hd.get_data((81, 80, p[::-1])).flatten())\n",
    "        \n",
    "    def test_set_slice(self):\n",
    "        hd = HERAData(self.uvh5_1)\n",
    "        hd.read()\n",
    "        np.random.seed(21)\n",
    "        \n",
    "        for bl in hd.bls:\n",
    "            new_vis = np.random.randn(60,1024) + np.random.randn(60,1024)*1.0j\n",
    "            hd._set_slice(hd.data_array, bl, new_vis)\n",
    "            np.testing.assert_array_almost_equal(new_vis, hd.get_data(bl))\n",
    "        \n",
    "        new_vis = np.random.randn(60,1024) + np.random.randn(60,1024)*1.0j\n",
    "        hd._set_slice(hd.data_array, (54, 53, 'xx'), new_vis)\n",
    "        np.testing.assert_array_almost_equal(np.conj(new_vis), hd.get_data((53, 54, 'xx')))\n",
    "        \n",
    "        new_vis = np.random.randn(60,1024) + np.random.randn(60,1024)*1.0j\n",
    "        hd._set_slice(hd.data_array, (53, 54), {'xx': new_vis})\n",
    "        np.testing.assert_array_almost_equal(new_vis, hd.get_data((53, 54, 'xx')))\n",
    "\n",
    "        new_vis = np.random.randn(60,1024) + np.random.randn(60,1024)*1.0j\n",
    "        to_set = {(53, 54): new_vis, (54, 54): 2*new_vis, (53, 53): 3*new_vis}\n",
    "        hd._set_slice(hd.data_array, 'XX', to_set)\n",
    "        np.testing.assert_array_almost_equal(new_vis, hd.get_data((53, 54, 'xx')))\n",
    "    \n",
    "        with self.assertRaises(KeyError):\n",
    "            hd._set_slice(hd.data_array, None, None)\n",
    "    \n",
    "    def test_build_datacontainers(self):\n",
    "        hd = HERAData(self.uvh5_1)\n",
    "        d, f, n = hd.read()\n",
    "        for bl in hd.bls:\n",
    "            np.testing.assert_array_almost_equal(d[bl], hd.get_data(bl))\n",
    "            np.testing.assert_array_almost_equal(f[bl], hd.get_flags(bl))\n",
    "            np.testing.assert_array_almost_equal(n[bl], hd.get_nsamples(bl))\n",
    "        for dc in [d, f, n]:\n",
    "            self.assertIsInstance(dc, DataContainer)\n",
    "            for k in dc.antpos.keys():\n",
    "                self.assertTrue(np.all(dc.antpos[k] == hd.antpos[k]))\n",
    "            self.assertTrue(np.all(dc.freqs == hd.freqs))\n",
    "            self.assertTrue(np.all(dc.times == hd.times))\n",
    "            self.assertTrue(np.all(dc.lsts == hd.lsts)) \n",
    "            for k in dc.times_by_bl.keys():\n",
    "                self.assertTrue(np.all(dc.times_by_bl[k] == hd.times_by_bl[k]))\n",
    "                self.assertTrue(np.all(dc.lsts_by_bl[k] == hd.lsts_by_bl[k]))\n",
    "\n",
    "    def test_read(self):\n",
    "        # uvh5\n",
    "        hd = HERAData(self.uvh5_1)\n",
    "        d, f, n = hd.read(bls=(53, 54, 'xx'), frequencies=hd.freqs[0:100], times=hd.times[0:10])\n",
    "        self.assertEqual(hd.last_read_kwargs['bls'], (53, 54, 'xx'))\n",
    "        self.assertEqual(hd.last_read_kwargs['polarizations'], None)\n",
    "        for dc in [d, f, n]:\n",
    "            self.assertEqual(len(dc), 1)\n",
    "            self.assertEqual(dc.keys(), [(53, 54, 'XX')])\n",
    "            self.assertEqual(dc[53, 54, 'xx'].shape, (10, 100))\n",
    "        with self.assertRaises(ValueError):\n",
    "            d, f, n = hd.read(polarizations=['xy'])\n",
    "        \n",
    "        # miriad\n",
    "        hd = HERAData(self.miriad_1, filetype='miriad')\n",
    "        d, f, n = hd.read()\n",
    "        hd = HERAData(self.miriad_1, filetype='miriad')\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            d, f, n = hd.read(bls=(52, 53), polarizations=['XX'], frequencies=d.freqs[0:30], times=d.times[0:10])\n",
    "            self.assertEqual(len(w), 1)        \n",
    "        self.assertEqual(hd.last_read_kwargs['polarizations'], ['XX'])\n",
    "        for dc in [d, f, n]:\n",
    "            self.assertEqual(len(dc), 1)\n",
    "            self.assertEqual(dc.keys(), [(52, 53, 'XX')])\n",
    "            self.assertEqual(dc[52, 53, 'xx'].shape, (10, 30))\n",
    "        with self.assertRaises(NotImplementedError):\n",
    "            d, f, n = hd.read(read_data=False)\n",
    "\n",
    "        # uvfits\n",
    "        hd = HERAData(self.uvfits, filetype='uvfits')\n",
    "        d, f, n = hd.read(bls=(0, 1, 'xx'), freq_chans=range(10))\n",
    "        self.assertEqual(hd.last_read_kwargs['freq_chans'], range(10))\n",
    "        for dc in [d, f, n]:\n",
    "            self.assertEqual(len(dc), 1)\n",
    "            self.assertEqual(dc.keys(), [(0, 1, 'XX')])\n",
    "            self.assertEqual(dc[0, 1, 'xx'].shape, (60, 10))\n",
    "        with self.assertRaises(NotImplementedError):\n",
    "            d, f, n = hd.read(read_data=False)\n",
    "\n",
    "    def test_getitem(self):\n",
    "        hd = HERAData(self.uvh5_1)\n",
    "        hd.read()\n",
    "        for bl in hd.bls:\n",
    "            np.testing.assert_array_almost_equal(hd[bl], hd.get_data(bl))\n",
    "\n",
    "    def test_update(self):\n",
    "        hd = HERAData(self.uvh5_1)\n",
    "        d, f, n = hd.read()\n",
    "        for bl in hd.bls:\n",
    "            d[bl] *= (2.0 + 1.0j)\n",
    "            f[bl] = np.logical_not(f[bl])\n",
    "            n[bl] += 1\n",
    "        hd.update(data=d, flags=f, nsamples=n)\n",
    "        d2, f2, n2 = hd.build_datacontainers()\n",
    "        for bl in hd.bls:\n",
    "            np.testing.assert_array_almost_equal(d[bl], d2[bl])\n",
    "            np.testing.assert_array_equal(f[bl], f2[bl])\n",
    "            np.testing.assert_array_equal(n[bl], n2[bl])            \n",
    "    \n",
    "    def test_partial_write(self):\n",
    "        hd = HERAData(self.uvh5_1)\n",
    "        self.assertEqual(hd.writers, {})\n",
    "        d, f, n = hd.read(bls=hd.bls[0])\n",
    "        self.assertEqual(hd.last_read_kwargs['bls'], (53, 53, 'XX'))\n",
    "        d[(53, 53, 'XX')] *= (2.0 + 1.0j)\n",
    "        hd.partial_write('out.h5', data=d, clobber=True)\n",
    "        self.assertTrue('out.h5' in hd.writers)\n",
    "        self.assertIsInstance(hd.writers['out.h5'], HERAData)\n",
    "        for meta in hd.HERAData_metas:\n",
    "            try:\n",
    "                np.testing.assert_array_equal(getattr(hd, meta), \n",
    "                                              getattr(hd.writers['out.h5'], meta))\n",
    "            except:\n",
    "                for k in getattr(hd, meta).keys():\n",
    "                    np.testing.assert_array_equal(getattr(hd, meta)[k], \n",
    "                                                  getattr(hd.writers['out.h5'], meta)[k])\n",
    "        \n",
    "        d, f, n = hd.read(bls=hd.bls[1])\n",
    "        self.assertEqual(hd.last_read_kwargs['bls'], (53, 54, 'XX'))\n",
    "        d[(53, 54, 'XX')] *= (2.0 + 1.0j)\n",
    "        hd.partial_write('out.h5', data=d, clobber=True)\n",
    "        \n",
    "        d, f, n = hd.read(bls=hd.bls[2])\n",
    "        self.assertEqual(hd.last_read_kwargs['bls'], (54, 54, 'XX'))\n",
    "        d[(54, 54, 'XX')] *= (2.0 + 1.0j)\n",
    "        hd.partial_write('out.h5', data=d, clobber=True)\n",
    "\n",
    "        hd = HERAData(self.uvh5_1)\n",
    "        d, f, n = hd.read()\n",
    "        hd2 = HERAData('out.h5')\n",
    "        d2, f2, n2 = hd2.read()\n",
    "        for bl in hd.bls:\n",
    "            np.testing.assert_array_almost_equal(d[bl] * (2.0 + 1.0j), d2[bl])\n",
    "            np.testing.assert_array_equal(f[bl], f2[bl])\n",
    "            np.testing.assert_array_equal(n[bl], n2[bl])            \n",
    "        os.remove('out.h5')\n",
    "            \n",
    "        # test errors\n",
    "        hd = HERAData(self.miriad_1, filetype='miriad')\n",
    "        with self.assertRaises(NotImplementedError):\n",
    "            hd.partial_write('out.uv')\n",
    "        hd = HERAData([self.uvh5_1, self.uvh5_2])\n",
    "        with self.assertRaises(NotImplementedError):\n",
    "            hd.partial_write('out.h5')\n",
    "        hd = HERAData(self.uvh5_1)\n",
    "        with self.assertRaises(ValueError):\n",
    "            hd.partial_write(None)\n",
    "    \n",
    "    def test_iterate_over_bls(self):\n",
    "        hd = HERAData(self.uvh5_1)\n",
    "        for (d, f, n) in hd.iterate_over_bls(Nbls=2):\n",
    "            for dc in (d, f, n):\n",
    "                self.assertTrue(len(dc.keys()) == 1 or len(dc.keys()) == 2)\n",
    "                self.assertEqual(list(dc.values())[0].shape, (60, 1024))\n",
    "        \n",
    "        hd = HERAData([self.uvh5_1, self.uvh5_2])\n",
    "        for (d, f, n) in hd.iterate_over_bls():\n",
    "            for dc in (d, f, n):\n",
    "                self.assertEqual(len(d.keys()), 1)\n",
    "                self.assertEqual(list(d.values())[0].shape, (120, 1024))\n",
    "        \n",
    "        hd = HERAData(self.miriad_1, filetype='miriad')\n",
    "        d, f, n = next(hd.iterate_over_bls(bls=[(52, 53, 'xx')]))\n",
    "        self.assertEqual(d.keys(), [(52, 53, 'XX')])\n",
    "        with self.assertRaises(NotImplementedError):\n",
    "            next(hd.iterate_over_bls())\n",
    "\n",
    "    def test_iterate_over_freqs(self):\n",
    "        hd = HERAData(self.uvh5_1)\n",
    "        for (d, f, n) in hd.iterate_over_freqs(Nchans=256):\n",
    "            for dc in (d, f, n):\n",
    "                self.assertEqual(len(dc.keys()), 3)\n",
    "                self.assertEqual(list(dc.values())[0].shape, (60, 256))\n",
    "        \n",
    "        hd = HERAData([self.uvh5_1, self.uvh5_2])\n",
    "        for (d, f, n) in hd.iterate_over_freqs(Nchans=512):\n",
    "            for dc in (d, f, n):\n",
    "                self.assertEqual(len(dc.keys()), 3)\n",
    "                self.assertEqual(list(dc.values())[0].shape, (120, 512))\n",
    "                \n",
    "        hd = HERAData(self.uvfits, filetype='uvfits')\n",
    "        d, f, n = hd.read()\n",
    "        d, f, n = next(hd.iterate_over_freqs(Nchans=2, freqs=d.freqs[0:2]))\n",
    "        for value in d.values():\n",
    "            self.assertEqual(value.shape, (60, 2))\n",
    "        with self.assertRaises(NotImplementedError):\n",
    "            next(hd.iterate_over_bls())\n",
    "\n",
    "                \n",
    "    def test_iterate_over_times(self):\n",
    "        hd = HERAData(self.uvh5_1)\n",
    "        for (d, f, n) in hd.iterate_over_times(Nints=20):\n",
    "            for dc in (d, f, n):\n",
    "                self.assertEqual(len(dc.keys()), 3)\n",
    "                self.assertEqual(list(dc.values())[0].shape, (20, 1024))\n",
    "        \n",
    "        hd.read(frequencies=hd.freqs[0:512])\n",
    "        hd.write_uvh5('out1.h5', clobber=True)\n",
    "        hd.read(frequencies=hd.freqs[512:])\n",
    "        hd.write_uvh5('out2.h5', clobber=True)\n",
    "        hd = HERAData(['out1.h5', 'out2.h5'])\n",
    "        for (d, f, n) in hd.iterate_over_times(Nints=30):\n",
    "            for dc in (d, f, n):\n",
    "                self.assertEqual(len(dc.keys()), 3)\n",
    "                self.assertEqual(list(dc.values())[0].shape, (30, 1024))\n",
    "        os.remove('out1.h5')\n",
    "        os.remove('out2.h5')\n",
    "        \n",
    "        hd = HERAData(self.uvfits, filetype='uvfits')\n",
    "        d, f, n = hd.read()\n",
    "        d, f, n = next(hd.iterate_over_times(Nints=2, times=d.times[0:2]))\n",
    "        for value in d.values():\n",
    "            self.assertEqual(value.shape, (2, 64))\n",
    "        with self.assertRaises(NotImplementedError):\n",
    "            next(hd.iterate_over_times())\n",
    "\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
