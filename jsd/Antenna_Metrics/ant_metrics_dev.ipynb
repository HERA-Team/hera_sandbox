{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import aipy as a \n",
    "from copy import deepcopy\n",
    "import glob\n",
    "from pyuvdata import UVCal\n",
    "from pyuvdata import UVData\n",
    "from hera_cal import omni\n",
    "from hera_cal import firstcal\n",
    "from hera_qm.datacontainer import DataContainer\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "#Low level functionality that is potentially reusable\n",
    "#######################################################################\n",
    "\n",
    "\n",
    "def per_antenna_modified_z_scores(metric):\n",
    "    '''For a given metric, stored as a (ant,antpol) dictonary, computes the per-pol modified z-score \n",
    "    for each antenna, which is the metrics, minus the median, divided by the median absolute deviation.'''\n",
    "    zscores = {}    \n",
    "    antpols = set([key[1] for key in metric.keys()])\n",
    "    for antpol in antpols:            \n",
    "        values = np.array([val for key,val in metric.items() if key[1]==antpol])\n",
    "        median = np.nanmedian(values)\n",
    "        medAbsDev = np.nanmedian(np.abs(values - median))\n",
    "        for key,val in metric.items(): \n",
    "            if key[1]==antpol:\n",
    "                zscores[key] = 0.6745*(val - median) / medAbsDev \n",
    "                #this factor makes it comparable to a standard z-score for gaussian data\n",
    "    return zscores\n",
    "\n",
    "def mean_Vij_metrics(data, pols, antpols, ants, xants=[], rawMetric=False):\n",
    "    '''Calculates how an antennas's average |Vij| deviates from others.\n",
    "\n",
    "    Arguments:\n",
    "    data -- data for all polarizations in the DataContainer format\n",
    "    pols -- List of visibility polarizations (e.g. ['xx','xy','yx','yy']).\n",
    "    antpols -- List of antenna polarizations (e.g. ['x', 'y'])\n",
    "    ants -- List of all antenna indices.\n",
    "    xants -- list of antennas in the (ant,antpol) format that should be ignored.\n",
    "    rawMetric -- return the raw mean Vij metric instead of the modified z-score\n",
    "\n",
    "    Returns:\n",
    "    meanMetrics -- a dictionary indexed by (ant,antpol) of the modified z-score of the mean of the \n",
    "    absolute value of all visibilities associated with an antenna. Very small or very large numbers \n",
    "    are probably bad antennas.\n",
    "    '''\n",
    "    \n",
    "    absVijMean = {(ant,antpol):0.0 for ant in ants for antpol in antpols if (ant,antpol) not in xants}\n",
    "    visCounts = deepcopy(absVijMean)\n",
    "    \n",
    "    for (i,j) in data.bls():\n",
    "        if i != j:\n",
    "            for pol in pols:\n",
    "                for ant, antpol in zip((i,j), pol):\n",
    "                    if (ant,antpol) not in xants:\n",
    "                        absVijMean[(ant,antpol)] += np.abs(data[i,j,pol])\n",
    "                        visCounts[(ant,antpol)] += 1\n",
    "    timeFreqMeans = {key: np.nanmean(absVijMean[key] / visCounts[key]) for key in absVijMean.keys()}\n",
    "\n",
    "    if rawMetric: \n",
    "        return timeFreqMeans\n",
    "    else: \n",
    "        return per_antenna_modified_z_scores(timeFreqMeans)\n",
    "\n",
    "def red_corr_metrics(data, pols, antpols, ants, reds, xants=[], rawMetric=False, crossPol=False):\n",
    "    '''Calculates the extent to which baselines involving an antenna don't correlated\n",
    "    with others they are nominmally redundant with.\n",
    "\n",
    "    Arguments:\n",
    "    data -- data for all polarizations in the DataContainer format\n",
    "    pols -- List of visibility polarizations (e.g. ['xx','xy','yx','yy']).\n",
    "    antpols -- List of antenna polarizations (e.g. ['x', 'y'])\n",
    "    ants -- List of all antenna indices.\n",
    "    reds -- List of lists of tuples of antenna numbers that make up redundant baseline groups.\n",
    "    xants -- list of antennas in the (ant,antpol) format that should be ignored.\n",
    "    rawMetric -- return the raw power correlations instead of the modified z-score\n",
    "    crossPol -- return results only when the two visibility polarizations differ by a single flip\n",
    "\n",
    "    Returns:\n",
    "    powerRedMetric -- a dictionary indexed by (ant,antpol) of the modified z-scores of the mean \n",
    "    power correlations inside redundant baseline groups that the antenna participates in.\n",
    "    Very small numbers are probably bad antennas.\n",
    "    '''\n",
    "\n",
    "    #Precompute auto-powers to save time\n",
    "    autoPower ={} \n",
    "    for pol in pols:\n",
    "        for bls in reds:\n",
    "            for bl in bls:\n",
    "                autoPower[bl[0],bl[1],pol] = np.median(np.sum(np.abs(data.get(bl,pol))**2, axis=0))\n",
    "\n",
    "    #Compute power correlations and assign them to each antenna\n",
    "    antCorrs = {(ant,antpol):0.0 for ant in ants for antpol in antpols if (ant,antpol) not in xants}\n",
    "    antCounts = deepcopy(antCorrs)\n",
    "    for pol0 in pols:\n",
    "        for pol1 in pols:\n",
    "            iscrossed_i = (pol0[0] != pol1[0])\n",
    "            iscrossed_j = (pol0[1] != pol1[1])\n",
    "            onlyOnePolCrossed = (iscrossed_i ^ iscrossed_j)\n",
    "            #This function can instead record correlations for antennas whose counterpart are pol-swapped\n",
    "            if (not crossPol and (pol0 is pol1)) or (crossPol and onlyOnePolCrossed):\n",
    "                for bls in reds:\n",
    "                    for n,(ant0_i,ant0_j) in enumerate(bls):\n",
    "                        data0 = data.get((ant0_i,ant0_j),pol0)\n",
    "                        for (ant1_i,ant1_j) in bls[n+1:]:\n",
    "                            data1 = data.get((ant1_i,ant1_j),pol1)\n",
    "                            corr = np.median(np.abs(np.sum(data0*data1.conj(), axis=0)))\n",
    "                            corr /= np.sqrt(autoPower[ant0_i,ant0_j,pol0] \n",
    "                                            * autoPower[ant1_i,ant1_j,pol1])\n",
    "                            antsInvolved = [(ant0_i,pol0[0]), (ant0_j,pol0[1]), \n",
    "                                            (ant1_i,pol1[0]), (ant1_j,pol1[1])]\n",
    "                            if not np.any([(ant,antpol) in xants for ant,antpol in antsInvolved]):\n",
    "                                #Only record the crossed antenna if i or j is crossed\n",
    "                                if crossPol and iscrossed_i:\n",
    "                                    antsInvolved = [(ant0_i,pol0[0]), (ant1_i,pol1[0])]\n",
    "                                elif crossPol and iscrossed_j:\n",
    "                                    antsInvolved = [(ant0_j,pol0[1]), (ant1_j,pol1[1])]\n",
    "                                for ant,antpol in antsInvolved:\n",
    "                                    antCorrs[(ant,antpol)] += corr\n",
    "                                    antCounts[(ant,antpol)] += 1   \n",
    "\n",
    "    #Compute average and return\n",
    "    for key,count in antCounts.items():\n",
    "        if count > 0: antCorrs[key] /= count\n",
    "    if rawMetric:\n",
    "        return antCorrs\n",
    "    else:\n",
    "        return per_antenna_modified_z_scores(antCorrs)\n",
    "\n",
    "\n",
    "def exclude_partially_excluded_ants(antpols, xants):\n",
    "    '''Takes a list of excluded antennas and adds on all polarizations of those antennas.'''\n",
    "    xantSet = set(xants)\n",
    "    for xant in xants:\n",
    "        for antpol in antpols:\n",
    "            xantSet.add((xant[0],antpol))\n",
    "    return list(xantSet)\n",
    "\n",
    "\n",
    "def antpol_metric_sum_ratio(ants, antpols, crossMetrics, sameMetrics, xants=[]):\n",
    "    '''Takes the ratio of two antenna metrics, summed over both polarizations, and creates a new\n",
    "    antenna metric with the same value in both polarizations for each antenna.'''\n",
    "    crossPolRatio = {}\n",
    "    for ant in ants: \n",
    "        if (ant,antpols[0]) not in xants:\n",
    "            crossSum = np.sum([crossMetrics[(ant,antpol)] for antpol in antpols])\n",
    "            sameSum = np.sum([sameMetrics[(ant,antpol)] for antpol in antpols])\n",
    "            for antpol in antpols: \n",
    "                crossPolRatio[(ant,antpol)] = crossSum/sameSum\n",
    "    return crossPolRatio\n",
    "\n",
    "\n",
    "def mean_Vij_cross_pol_metrics(data, pols, antpols, ants, xants=[], rawMetric=False):\n",
    "    '''Find which antennas are outliers based on the ratio of mean cross-pol visibilities to \n",
    "    mean same-pol visibilities: (Vxy+Vyx)/(Vxx+Vyy).\n",
    "\n",
    "    Arguments:\n",
    "    data -- data for all polarizations in the DataContainer format\n",
    "    pols -- List of visibility polarizations (e.g. ['xx','xy','yx','yy']).\n",
    "    antpols -- List of antenna polarizations (e.g. ['x', 'y'])\n",
    "    ants -- List of all antenna indices.\n",
    "    xants -- list of antennas in the (ant,antpol) format that should be ignored. If, e.g., (81,'y')\n",
    "            is excluded, (81,'x') cannot be identified as cross-polarized and will be excluded.\n",
    "    rawMetric -- return the raw power ratio instead of the modified z-score\n",
    "\n",
    "    Returns:\n",
    "    mean_Vij_cross_pol_metrics -- a dictionary indexed by (ant,antpol) of the modified z-scores of the  \n",
    "            ratio of mean visibilities, (Vxy+Vyx)/(Vxx+Vyy). Results duplicated in both antpols. \n",
    "            Very large values are probably cross-polarized.\n",
    "    '''\n",
    "\n",
    "    # Compute metrics and cross pols only and and same pols only\n",
    "    samePols = [pol for pol in pols if pol[0] == pol[1]]\n",
    "    crossPols = [pol for pol in pols if pol[0] != pol[1]]\n",
    "    full_xants = exclude_partially_excluded_ants(antpols, xants)\n",
    "    meanVijMetricsSame = mean_Vij_metrics(data, samePols, antpols, ants, xants=full_xants, rawMetric=True)\n",
    "    meanVijMetricsCross = mean_Vij_metrics(data, crossPols, antpols, ants, xants=full_xants, rawMetric=True)\n",
    "\n",
    "    # Compute the ratio of the cross/same metrics, saving the same value in each antpol\n",
    "    crossPolRatio = antpol_metric_sum_ratio(ants, antpols, meanVijMetricsCross, meanVijMetricsSame, xants=full_xants)\n",
    "    if rawMetric:\n",
    "        return crossPolRatio\n",
    "    else:\n",
    "        return per_antenna_modified_z_scores(crossPolRatio)\n",
    "\n",
    "    \n",
    "def red_corr_cross_pol_metrics(data, pols, antpols, ants, reds, xants=[], rawMetric=False):\n",
    "    '''Find which antennas are part of visibilities that are significantly better correlated with \n",
    "    polarization-flipped visibilities in a redundant group. Returns the modified z-score.\n",
    "\n",
    "    Arguments:\n",
    "    data -- data for all polarizations in the DataContainer format\n",
    "    pols -- List of visibility polarizations (e.g. ['xx','xy','yx','yy']).\n",
    "    antpols -- List of antenna polarizations (e.g. ['x', 'y'])\n",
    "    ants -- List of all antenna indices.\n",
    "    reds -- List of lists of tuples of antenna numbers that make up redundant baseline groups.\n",
    "    xants -- list of antennas in the (ant,antpol) format that should be ignored. If, e.g., (81,'y')\n",
    "            is excluded, (81,'x') cannot be identified as cross-polarized and will be excluded.\n",
    "    rawMetric -- return the raw correlation ratio instead of the modified z-score\n",
    "\n",
    "    Returns:\n",
    "    redCorrCrossPolMetrics -- a dictionary indexed by (ant,antpol) of the modified z-scores of the \n",
    "            mean correlation ratio between redundant visibilities and singlely-polarization flipped \n",
    "            ones. Very large values are probably cross-polarized.\n",
    "    '''\n",
    "\n",
    "    # Compute metrics for singly flipped pols and just same pols\n",
    "    full_xants = exclude_partially_excluded_ants(antpols, xants)\n",
    "    samePols = [pol for pol in pols if pol[0] == pol[1]]\n",
    "    redCorrMetricsSame = red_corr_metrics(data, samePols, antpols, ants, reds, xants=full_xants, rawMetric=True)\n",
    "    redCorrMetricsCross = red_corr_metrics(data, pols, antpols, ants, reds, xants=full_xants, rawMetric=True, crossPol=True)\n",
    "\n",
    "    # Compute the ratio of the cross/same metrics, saving the same value in each antpol\n",
    "    crossPolRatio = antpol_metric_sum_ratio(ants, antpols, redCorrMetricsCross, redCorrMetricsSame, xants=full_xants)\n",
    "    if rawMetric:\n",
    "        return crossPolRatio\n",
    "    else:\n",
    "        return per_antenna_modified_z_scores(crossPolRatio)\n",
    "\n",
    "def average_metrics(metrics1, metrics2):\n",
    "    '''Averages two metrics together.'''\n",
    "    \n",
    "    if set(metrics1.keys()) != set(metrics2.keys()):\n",
    "        raise KeyError, 'Metrics being averaged have differnt (ant,antpol) keys.'\n",
    "    return {key: metrics1[key]/2 + metrics2[key]/2 for key in metrics1.keys()}\n",
    "\n",
    "def load_antenna_metrics(metricsJSONFile):\n",
    "    '''Loads all cut decisions and meta-metrics from a JSON into python dictionary.'''\n",
    "    \n",
    "    with open(metricsJSONFile,'r') as infile:\n",
    "        jsonMetrics = json.load(infile)\n",
    "    return {key: eval(str(val)) for key,val in jsonMetrics.items()}\n",
    "\n",
    "def plot_metric(metrics, ants=None, antpols=None, title='', ylabel='Modified z-Score', xlabel=''):\n",
    "    '''Helper function for quickly plotting an individual antenna metric.'''\n",
    "\n",
    "    if ants is None:\n",
    "        ants = list(set([key[0] for key in metrics.keys()]))\n",
    "    if antpols is None:\n",
    "        antpols = list(set([key[1] for key in metrics.keys()]))\n",
    "    \n",
    "    plt.figure()    \n",
    "    for antpol in antpols:\n",
    "        for i,ant in enumerate(ants):\n",
    "            metric = 0\n",
    "            if metrics.has_key((ant,antpol)):\n",
    "                metric = metrics[(ant,antpol)]\n",
    "            plt.plot(i,metric,'.')\n",
    "            plt.annotate(str(ant)+antpol,xy=(i,metrics[(ant,antpol)]))\n",
    "        plt.gca().set_prop_cycle(None)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "#High level functionality for HERA\n",
    "#######################################################################\n",
    "\n",
    "\n",
    "class Antenna_Metrics():\n",
    "    '''Object for holding relevant visibility data and metadata with interfaces to four \n",
    "    antenna metrics (two for identifying dead antennas, two for identifying cross-polarized ones), \n",
    "    an iterative method for identifying one bad antenna at a time while keeping track of all \n",
    "    metrics, and for writing metrics to a JSON.'''\n",
    "    \n",
    "    def __init__(self, dataFileDict, reds):\n",
    "        '''Arguments:\n",
    "        dataFileDict -- Dictionary of miriad data filenames index by visibility polarization strings\n",
    "        reds -- List of lists of tuples of antenna numbers that make up redundant baseline groups\n",
    "        '''\n",
    "        \n",
    "        self.pols = dataFileDict.keys()\n",
    "        #TODO: eventually, this should be handled in a more pyuvdata-consistent way\n",
    "        data, flags = {}, {}\n",
    "        for pol in self.pols:\n",
    "            uv_in = UVData()\n",
    "            uv_in.read_miriad(dataFileDict[pol])\n",
    "            datapack, flagpack = firstcal.UVData_to_dict([uv_in])\n",
    "            #TODO: update this class to support flagged arrays once we start using pyuvdata more thoroughly\n",
    "            if len(data) == 0: \n",
    "                data = datapack\n",
    "            else:\n",
    "                for key in datapack: data[key].update(datapack[key])\n",
    "        \n",
    "        self.data = DataContainer(data)\n",
    "        self.ants = sorted(list(set([bl[0] for bl in self.data.bls()]).union(set([bl[1] for bl in self.data.bls()]))))\n",
    "        self.antpols = list(set(''.join(pols)))\n",
    "        self.reds = reds\n",
    "        if len(self.antpols) is not 2 or len(self.pols) is not 4:\n",
    "            raise ValueError, 'Missing polarization information. pols =' + str(self.pols) + ' and antpols = ' + str(self.antpols)\n",
    "\n",
    "    def mean_Vij_metrics(self, pols=None, xants=[], rawMetric=False):\n",
    "        '''Local wrapper for mean_Vij_metrics in hera_qm.ant_metrics module.'''\n",
    "\n",
    "        if pols is None:\n",
    "            pols = self.pols\n",
    "        return mean_Vij_metrics(self.data, pols, self.antpols, self.ants, xants=xants, rawMetric=rawMetric)\n",
    "\n",
    "\n",
    "    def red_corr_metrics(self, pols=None, xants=[], rawMetric=False, crossPol=False):\n",
    "        '''Local wrapper for red_corr_metrics in hera_qm.ant_metrics module.'''\n",
    "\n",
    "        if pols is None:\n",
    "            pols = self.pols\n",
    "        return red_corr_metrics(self.data, pols, self.antpols, self.ants, self.reds, xants=xants, rawMetric=rawMetric, crossPol=crossPol)\n",
    "\n",
    "    def mean_Vij_cross_pol_metrics(self, xants=[], rawMetric=False):\n",
    "        '''Local wrapper for mean_Vij_cross_pol_metrics in hera_qm.ant_metrics module.'''\n",
    "        \n",
    "        return mean_Vij_cross_pol_metrics(self.data, self.pols, self.antpols, self.ants, xants=xants, rawMetric=rawMetric)\n",
    "\n",
    "\n",
    "    def red_corr_cross_pol_metrics(self, xants=[], rawMetric=False):\n",
    "        '''Local wrapper for red_corr_cross_pol_metrics in hera_qm.ant_metrics module.'''\n",
    "\n",
    "        return red_corr_cross_pol_metrics(self.data, self.pols, self.antpols, self.ants, self.reds, xants=xants, rawMetric=False)\n",
    "    \n",
    "    def _run_all_metrics(self):\n",
    "        '''Designed to be run as part of AntennaMetrics.iterative_antenna_metrics_and_flagging().'''\n",
    "        \n",
    "        #Compute all raw metrics\n",
    "        meanVij = self.mean_Vij_metrics(xants=self.xants, rawMetric=True)\n",
    "        redCorr = self.red_corr_metrics(pols=['xx','yy'], xants=self.xants, rawMetric=True)\n",
    "        meanVijXPol = self.mean_Vij_cross_pol_metrics(xants=self.xants, rawMetric=True)\n",
    "        redCorrXPol = self.red_corr_cross_pol_metrics(xants=self.xants, rawMetric=True)   \n",
    "        \n",
    "        #Save all metrics and zscores\n",
    "        metrics, modzScores = {}, {}\n",
    "        for metName in ['meanVij','redCorr','meanVijXPol','redCorrXPol']:\n",
    "            metric = eval(metName)\n",
    "            metrics[metName] = metric\n",
    "            modz = per_antenna_modified_z_scores(metric)\n",
    "            modzScores[metName] = modz\n",
    "            for key in metric.keys():\n",
    "                if self.finalMetrics.has_key(metName):\n",
    "                    self.finalMetrics[metName][key] = metric[key]\n",
    "                    self.finalModzScores[metName][key] = modz[key]\n",
    "                else:\n",
    "                    self.finalMetrics[metName] = {key: metric[key]}\n",
    "                    self.finalModzScores[metName] = {key: modz[key]}\n",
    "        self.allMetrics.append(metrics)\n",
    "        self.allModzScores.append(modzScores)        \n",
    "    \n",
    "    def iterative_antenna_metrics_and_flagging(self, crossCut=5, deadCut=5, verbose=False):\n",
    "        '''Runs all four metrics (two for dead antennas two for cross-polarized antennas) and saves\n",
    "        the results internally to this this antenna metrics object. \n",
    "        \n",
    "        Arguments:\n",
    "        crossCut -- Modified z-score cut for most cross-polarized antenna. Default 5 \"sigmas\".\n",
    "        deadCut -- Modified z-score cut for most likely dead antenna. Default 5 \"sigmas\".\n",
    "        '''\n",
    "        \n",
    "        #Summary statistics\n",
    "        self.xants, self.crossedAntsRemoved, self.deadAntsRemoved = [], [], []\n",
    "        self.removalIter = {}\n",
    "        self.allMetrics, self.allModzScores = [], []\n",
    "        self.finalMetrics, self.finalModzScores = {}, {}\n",
    "        self.crossCut, self.deadCut = crossCut, deadCut\n",
    "        \n",
    "        #Loop over \n",
    "        for n in range(len(self.antpols)*len(self.ants)):\n",
    "            self._run_all_metrics()\n",
    "            \n",
    "            # Mostly likely dead antenna\n",
    "            deadMetrics = average_metrics(self.allModzScores[-1]['meanVij'], \n",
    "                                          self.allModzScores[-1]['redCorr'])\n",
    "            worstDeadAnt = min(deadMetrics, key=deadMetrics.get)\n",
    "            worstDeadCutRatio = np.abs(deadMetrics[worstDeadAnt])/deadCut\n",
    "\n",
    "            # Most likely cross-polarized antenna \n",
    "            crossMetrics = average_metrics(self.allModzScores[-1]['meanVijXPol'], \n",
    "                                           self.allModzScores[-1]['redCorrXPol'])    \n",
    "            worstCrossAnt = max(crossMetrics, key=crossMetrics.get)\n",
    "            worstCrossCutRatio = np.abs(crossMetrics[worstCrossAnt])/crossCut\n",
    "            \n",
    "            # Find the single worst antenna, remove it, log it, and run again\n",
    "            if worstCrossCutRatio >= worstDeadCutRatio and worstCrossCutRatio >= 1.0:\n",
    "                for antpol in self.antpols:\n",
    "                    self.xants.append((worstCrossAnt[0],antpol))\n",
    "                    self.crossedAntsRemoved.append((worstCrossAnt[0],antpol))\n",
    "                    self.removalIter[(worstCrossAnt[0],antpol)] = n\n",
    "                    if verbose:\n",
    "                        print 'On iteration', n, 'we flag', (worstCrossAnt[0],antpol)\n",
    "            elif worstDeadCutRatio > worstCrossCutRatio and worstDeadCutRatio > 1.0:\n",
    "                self.xants.append(worstDeadAnt)\n",
    "                self.deadAntsRemoved.append(worstDeadAnt)\n",
    "                self.removalIter[worstDeadAnt] = n\n",
    "                if verbose:\n",
    "                    print 'On iteration', n, 'we flag', worstDeadAnt\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    def save_antenna_metrics(self, metricsJSONFilename):\n",
    "        '''Saves all cut decisions and meta-metrics in a human-readable JSON that can be loaded \n",
    "        back into a dictionary using hera_qm.ant_metrics.load_antenna_metrics().'''\n",
    "        \n",
    "        if not hasattr(self, 'xants'): \n",
    "            raise KeyError, 'Must run AntennaMetrics.iterative_antenna_metrics_and_flagging() first.'\n",
    "        \n",
    "        allMetricsData = {'xants': str(self.xants)}\n",
    "        allMetricsData['ants_removed_as_crossed'] = str(self.deadAntsRemoved)\n",
    "        allMetricsData['ants_removed_as_dead'] = str(self.crossedAntsRemoved)\n",
    "        allMetricsData['final_metrics'] = str(self.finalMetrics)\n",
    "        allMetricsData['all_metrics'] = str(self.allMetrics)\n",
    "        allMetricsData['final_mod_z_scores'] = str(self.finalModzScores)\n",
    "        allMetricsData['all_mod_z_scores'] = str(self.allModzScores)\n",
    "        allMetricsData['removal_iteration'] = str(self.removalIter)\n",
    "        allMetricsData['cross_pol_z_cut'] = str(self.crossCut)\n",
    "        allMetricsData['dead_ant_z_cut'] = str(self.deadCut)\n",
    "        \n",
    "        with open(metricsJSONFilename, 'w') as outfile:\n",
    "            json.dump(allMetricsData, outfile, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pols = ['xx','xy','yx','yy']\n",
    "JD = '2457757.47316'\n",
    "dataFileDict = {}\n",
    "for pol in pols:\n",
    "    dataFileDict[pol] = '/data4/paper/HERA2015/'+JD.split('.')[0]+'/zen.'+JD+'.'+pol+'.HH.uvc' #works well    \n",
    "\n",
    "freqs = np.arange(.1,.2,.1/1024)    \n",
    "aa = a.cal.get_aa('hsa7458_v001', freqs)\n",
    "info = omni.aa_to_info(aa, pols=[pols[-1][0]], crosspols=[pols[-1]])\n",
    "reds = info.get_reds()\n",
    "\n",
    "metricsJSONFilename = '/home/jdill/capo/jsd/Antenna_Metrics/'+JD+'.metrics.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Altitude is not present in Miriad file, using known location values for HERA.\n",
      "antenna number 112 has visibilities associated with it, but it has a position of (0,0,0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On iteration 0 we flag (64, 'y')\n",
      "On iteration 1 we flag (22, 'y')\n",
      "On iteration 2 we flag (81, 'y')\n",
      "On iteration 2 we flag (81, 'x')\n",
      "On iteration 3 we flag (64, 'x')\n",
      "On iteration 4 we flag (22, 'x')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-250e66554325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAntenna_Metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataFileDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterative_antenna_metrics_and_flagging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrossCut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeadCut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_antenna_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetricsJSONFilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-c7a05d55251a>\u001b[0m in \u001b[0;36msave_antenna_metrics\u001b[0;34m(self, metricsJSONFilename)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetricsJSONFilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallMetricsData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: global name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "am = Antenna_Metrics(dataFileDict, reds)\n",
    "am.iterative_antenna_metrics_and_flagging(crossCut=5, deadCut=5, verbose=True)\n",
    "am.save_antenna_metrics(metricsJSONFilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metrics_results = load_antenna_metrics(metricsJSONFilename)\n",
    "\n",
    "plot_metric(metrics_results['final_mod_z_scores']['meanVij'], \n",
    "           title = 'Mean Vij Modified z-Score')\n",
    "plot_metric(metrics_results['final_mod_z_scores']['redCorr'],\n",
    "           title = 'Redundant Visibility Correlation Modified z-Score')\n",
    "plot_metric(metrics_results['final_mod_z_scores']['meanVijXPol'], antpols=['x'],\n",
    "           title = 'Modified z-score of (Vxy+Vyx)/(Vxx+Vyy)')\n",
    "plot_metric(metrics_results['final_mod_z_scores']['redCorrXPol'], antpols=['x'],\n",
    "           title = 'Modified z-Score of Power Correlation Ratio Cross/Same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
