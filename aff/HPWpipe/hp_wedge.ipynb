{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "import astropy.constants as c\n",
    "import astropy.coordinates as aco\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import hera_pspec as hp\n",
    "from hera_pspec.data import DATA_PATH\n",
    "from pyuvdata import UVData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '-F',\n",
    "    '--files',\n",
    "    help='Designate the hdf5 files to be analyzed.',\n",
    "    nargs='*',\n",
    "    required=True)\n",
    "parser.add_argument(\n",
    "    '-L',\n",
    "    '--LSTrange',\n",
    "    help='Designate which LST in hours that will be analyzed (e.g.: \"6.0 7.0\").',\n",
    "    type=float,\n",
    "    nargs=2,\n",
    "    required=True)\n",
    "parser.add_argument(\n",
    "    '-C',\n",
    "    '--freq_chans',\n",
    "    help='Designate which frequency channels that will be analyzed (e.g.: \"580 680\".',\n",
    "    type=int,\n",
    "    nargs=2,\n",
    "    required=True)\n",
    "args = parser.parse_args(\n",
    "    \"-F /lustre/aoc/projects/hera/H1C_IDR2/IDR2_1/2458111/zen.2458111.?????.xx.HH.uvh5.OCRS \\\n",
    "    -L 5.0 6.0 \\\n",
    "    -C 580 680\".split())\n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next line is for running as .py, the one after is for running as jupyter notebook\n",
    "# dfiles = np.array(sorted(args.files))\n",
    "dfiles = sorted(glob.glob(args.files[0]))\n",
    "LSTrange = args.LSTrange\n",
    "freq_chans = np.arange(args.freq_chans[0], args.freq_chans[-1] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "uvd = UVData()\n",
    "files = []\n",
    "times = []\n",
    "for dfile in dfiles:\n",
    "    uvd.read_uvh5(dfile, read_data=False)\n",
    "    LSTrads = np.unique(uvd.lst_array * u.rad)\n",
    "    LSThours = aco.Angle(LSTrads).hour\n",
    "    LSTindices = np.where(np.logical_and(LSThours >= LSTrange[0], LSThours <= LSTrange[-1]))[0]\n",
    "    \n",
    "    if LSTindices.size > 0:\n",
    "        JDtimes = np.take(np.unique(uvd.time_array), LSTindices)\n",
    "        files.append(dfile)\n",
    "        times.append(JDtimes.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "uvd = UVData()\n",
    "uvd.read_uvh5(\n",
    "    files[0],\n",
    "    ant_str='cross',\n",
    "    freq_chans=freq_chans,\n",
    "    times=times[0])\n",
    "for file, time in zip(files[1:], times[1:]):\n",
    "    uvdi = UVData()\n",
    "    uvdi.read_uvh5(\n",
    "        file, \n",
    "        ant_str='cross',\n",
    "        freq_chans=freq_chans,\n",
    "        times=time)\n",
    "    uvd += uvdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# Apply flags\n",
    "uvd.data_array *= np.logical_not(uvd.flag_array)\n",
    "\n",
    "# Intialize a cosmology and a beam\n",
    "cosmo = hp.conversions.Cosmo_Conversions()\n",
    "beamfile = os.path.join(DATA_PATH, 'NF_HERA_Beams.beamfits')\n",
    "uvb = hp.pspecbeam.PSpecBeamUV(beamfile, cosmo=cosmo)\n",
    "\n",
    "# Convert to cosmological units (mK)\n",
    "Jy_to_mK = uvb.Jy_to_mK(np.unique(uvd.freq_array), pol=\"xx\")\n",
    "uvd.data_array *= Jy_to_mK[None, None, :, None]\n",
    "\n",
    "# Shift data and load datasets\n",
    "uvd1 = uvd.select(times=np.unique(uvd.time_array)[:-1:2], inplace=False)\n",
    "uvd2 = uvd.select(times=np.unique(uvd.time_array)[1::2], inplace=False)\n",
    "ds = hp.PSpecData(dsets=[uvd1, uvd2], wgts=[None, None], beam=uvb)\n",
    "\n",
    "ds.dsets[0].vis_units = 'mK'\n",
    "ds.dsets[1].vis_units = 'mK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# Phase data (What does this do?)\n",
    "ds.rephase_to_dset(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# Categorize baselines into physical separation length\n",
    "BIN_WIDTH = 0.3\n",
    "NORM_BINS = np.arange(0.0, 10000.0, BIN_WIDTH)\n",
    "\n",
    "antpos = {ant: pos for ant, pos in zip(uvd.get_ENU_antpos()[1], uvd.get_ENU_antpos()[0])}\n",
    "\n",
    "antpairs = uvd.get_antpairs()\n",
    "xants1, xants2 = hp.utils.calc_reds(uvd1, uvd2)[3:]\n",
    "xants = np.unique(xants1 + xants2)\n",
    "\n",
    "reds = {}\n",
    "for antpair in antpairs:\n",
    "    ant0, ant1 = antpair\n",
    "    if (ant0 in xants) or (ant1 in xants) or (ant0 >= ant1):\n",
    "        continue\n",
    "    norm = np.linalg.norm(antpos[ant0] - antpos[ant1])\n",
    "    norm = np.round(np.digitize(norm, NORM_BINS) * BIN_WIDTH, 1)\n",
    "\n",
    "    if norm in reds:\n",
    "        reds[norm].append(antpair)\n",
    "    else:\n",
    "        reds[norm] = [antpair]\n",
    "norms = sorted(reds.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# Initialize UVPspec objects for each baseline bin\n",
    "uvps = [] \n",
    "for norm in norms:\n",
    "    uvp = ds.pspec(\n",
    "        reds[norm],\n",
    "        reds[norm],\n",
    "        (0, 1),\n",
    "        pols=(\"xx\", \"xx\"),\n",
    "        spw_ranges=[(0, freq_chans.size)],\n",
    "        taper=\"blackman-harris\",\n",
    "        verbose=False)\n",
    "    uvps.append(uvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# Average each UVPspec object in time and baseline bin and fold into wedge\n",
    "for uvp, norm in zip(uvps, norms):\n",
    "    blpairs = [[(bl, bl) for bl in reds[norm]]]\n",
    "    uvp.average_spectra(blpair_groups=blpairs, time_avg=True)\n",
    "    uvp.fold_spectra()\n",
    "    uvp.data_array[0] = uvp.data_array[0].reshape(\n",
    "        (len(uvp.freq_array)))[np.nonzero(uvp.data_array[0].reshape((len(uvp.freq_array))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from UVPspec objects into an array\n",
    "wedge = np.array([uvp.data_array[0] for uvp in uvps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plotting\"\"\"\n",
    "def get_cmap(n, name='jet'):\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "cmap = get_cmap(len(uvps))\n",
    "\n",
    "# Make a copy of a uvp object to get freq_array and kparas\n",
    "UVP = copy.deepcopy(uvps[0])\n",
    "\n",
    "# Find bandwidth and central frequency in MHz for naming\n",
    "BAND_START = (UVP.freq_array[0] * u.Hz).to(u.MHz)\n",
    "BAND_STOP = (UVP.freq_array[-1] * u.Hz).to(u.MHz)\n",
    "BANDWIDTH = (BAND_STOP - BAND_START)\n",
    "CENTRAL_FREQ = ((BANDWIDTH / UVP.Nfreqs) + BAND_START)\n",
    "\n",
    "# Generate x-values to plot against\n",
    "kparas = (UVP.get_kparas(0)/u.Mpc).insert(0, 0)\n",
    "\n",
    "Tsys = 360\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, (uvp, norm, pspec) in enumerate(zip(uvps, norms, wedge)):\n",
    "    plt.plot(\n",
    "        kparas,\n",
    "        np.log10(np.abs(pspec)),\n",
    "        c=cmap(i),\n",
    "        ls='-',\n",
    "        lw=1,\n",
    "        label='{norm}m ({ants} ants)'.format(norm=norm, ants=len(reds[norm])))\n",
    "\n",
    "#     noise = uvp.generate_noise_spectra(0, 'xx', Tsys)\n",
    "#     noise = noise[noise.keys()[0]]\n",
    "#     noise = np.insert(noise, 0, noise[0, 0], axis=1)\n",
    "#     noise = noise.reshape(len(kparas))\n",
    "#     noise = np.log10(noise)\n",
    "#     plt.plot(\n",
    "#         kparas,\n",
    "#         noise,\n",
    "#         c=cmap(i),\n",
    "#         ls='--',\n",
    "#         lw=1,\n",
    "#         label='{norm}m {Tsys}K'.format(norm=norm, Tsys=Tsys))\n",
    "    \n",
    "    \n",
    "plt.legend(loc='upper right', ncol=3)\n",
    "\n",
    "# x-axis\n",
    "plt.xlim((0, UVP.get_kparas(0)[-1]))\n",
    "plt.xlabel(r\"$k_{\\parallel}\\ [\\rm\\ Mpc^{-1}\\ h]$\", size=20)\n",
    "\n",
    "# y-axis\n",
    "# plt.ylim((0, 20))\n",
    "plt.ylabel(r\"$P(k)\\ \\rm [\\log_{10}({mK^2\\ Mpc^3\\ h^{-3}})]$\", size=20)\n",
    "\n",
    "# Titles\n",
    "plt.title(\"pol: xx; Bandwidth: {BW}; Central Frequency: {CF}\".format(\n",
    "    BW=np.round(BANDWIDTH, 2),\n",
    "    CF=np.round(CENTRAL_FREQ, 1)))\n",
    "plt.suptitle(os.path.basename(files[0]) + \"\\nto\\n\" + os.path.basename(files[-1]))\n",
    "\n",
    "# Save and show the plot with a grid\n",
    "plt.grid()\n",
    "plt.savefig(\"zen.{JD}.{JD0}_{JDf}.xx.HH{DFext}.pdf\".format(\n",
    "    BW=np.round(BANDWIDTH.value, 2),\n",
    "    CF=np.round(CENTRAL_FREQ.value, 1),\n",
    "    JD=files[0].split(\".\")[1],\n",
    "    JD0=files[0].split(\".\")[2],\n",
    "    JDf=files[-1].split(\".\")[2],\n",
    "    DFext=os.path.splitext(files[0])[1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(np.log10(np.abs(wedge)), interpolation=\"nearest\", aspect=\"auto\")\n",
    "\n",
    "# plt.tick_params(axis='both', direction='inout')\n",
    "\n",
    "# plt.xticks([])\n",
    "# plt.xlabel(str(norms[i]) + \" m\", rotation=45, ha=\"center\")\n",
    "\n",
    "# horizon = ((norms[i]*u.m / c.c).to(u.ns)).value\n",
    "# plt.axhline(y=horizon, color=\"w\", ls=\":\")\n",
    "# plt.axhline(y=-horizon, color=\"w\", ls=\":\")\n",
    "\n",
    "# plt.ylim((uvp.get_dlys(0)[0]*1e9 / 2., uvp.get_dlys(0)[-1]*1e9 / 2.))\n",
    "    \n",
    "# plt.text(0.07, 0.5, r\"$\\tau$ [ns]\", ha=\"center\", rotation=\"vertical\", size=20)\n",
    "# plt.text(0.5, 0.04, \"Redundant Baseline Group\", ha=\"center\", size=20)\n",
    "# plt.subplots_adjust(wspace=0, hspace=0)\n",
    "# cbar_ax = fig.add_axes([0.9125, 0.25, 0.025, 0.5])\n",
    "# cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "# cbar.set_label(r\"$P(k)\\ \\rm [mK^2\\ h^{-3}\\ Mpc^3]$\", fontsize=20, ha='center')\n",
    "# plt.show()\n",
    "# plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each baselines divided by or subtracted by its noise estimate in 2d wedge format"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
