{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This script will take one uvf5 file with a UVData object and turn it into multiple\n",
    "uvf5 files with UVPspec objects in them that each represent the power spectra of a group\n",
    "of redundant baselines.\"\"\"\n",
    "# Python Standard Library Packages\n",
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "\n",
    "# Community Developed Packages\n",
    "import numpy as np\n",
    "\n",
    "# HERA Collaboration Packages\n",
    "import hera_pspec as hp\n",
    "from hera_pspec.data import DATA_PATH\n",
    "from pyuvdata import UVData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '-F',\n",
    "    '--files',\n",
    "    help='Designate the hdf5 files to be analyzed.',\n",
    "    nargs='*',\n",
    "    required=True)\n",
    "parser.add_argument(\n",
    "    '-P',\n",
    "    '--pols',\n",
    "    help='Designate which polarizations to analyze (e.g.: \"pI pQ XY YY XX\").',\n",
    "    nargs='*',\n",
    "    required=True)\n",
    "parser.add_argument(\n",
    "    '-R',\n",
    "    '--FREQrng',\n",
    "    help='Designate the frequency range, in channels, that will be analyzed (e.g.: \"580 680\").',\n",
    "    type=int,\n",
    "    nargs=2,\n",
    "    required=True)\n",
    "parser.add_argument(\n",
    "    '-S',\n",
    "    '--savepath',\n",
    "    help='Designate the path where the new hdf5 files will be saved. Default is path to data files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Uncomment this code when running as .py:\"\"\"\n",
    "# args = parser.parse_args()\n",
    "# dfiles = np.array(sorted(args.files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Uncomment this code when running as .ipynb:\"\"\"\n",
    "args = parser.parse_args(\n",
    "    \"-F /lustre/aoc/projects/hera/afortino/H1C_IDR2_1/OCRS/2458098/LSThrs_5.0_to_6.0/*OCRS \\\n",
    "     -P pI pQ pU pV XX XY YX YY \\\n",
    "     -R 530 730\".format(day=day).split())\n",
    "dfiles = sorted(glob.glob(args.files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to sort the files by polarization\n",
    "pol_sort = {'pI': 1, 'pQ': 2, 'pU': 3, 'pV': 5, 'XX': 5, 'YY': 6, 'XY': 7, 'YX': 8, 'xx': 5, 'yy': 6, 'xy': 7, 'yx': 8}\n",
    "\n",
    "# Sorting function to grab the polarization and find its index from pol_sort dictionary\n",
    "def pol_sort_fn(x, y):\n",
    "    polx = pol_sort[x]\n",
    "    poly = pol_sort[y]\n",
    "\n",
    "    return int(polx - poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Formatting command line arguments:\"\"\"\n",
    "pols = sorted(args.pols, cmp=pol_sort_fn)\n",
    "FREQrng = args.FREQrng\n",
    "if args.savepath is None:\n",
    "    savepath = os.path.dirname(args.files[0])\n",
    "else:\n",
    "    savepath = args.savepath\n",
    "savepath = os.path.join(savepath, 'FREQrng_{}_to_{}'.format(FREQrng[0], FREQrng[1]))\n",
    "os.system('mkdir -p {}'.format(savepath))\n",
    "print 'Saving files to:\\n{}'.format(savepath)\n",
    "print 'Polarizations: {}'.format(pols)\n",
    "print 'Frequency Channel Range: {}'.format(FREQrng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Defining pol constants:\"\"\"\n",
    "STD_POLS = ['xx', 'yy', 'xy', 'yx']\n",
    "pS_POLS = ['pI', 'pQ', 'pU', 'pV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loading input files as UVData objects:\"\"\"\n",
    "uvds_std_pols = {std_pol: None for std_pol in STD_POLS}\n",
    "for dfile in dfiles:\n",
    "    uvd = UVData()\n",
    "    uvd.read_uvh5(dfile)\n",
    "    pol = uvd.get_pols()[0].lower()\n",
    "    uvds_std_pols[pol] = uvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Creating pseudo stokes UVData objects (if requested) and formatting UVdata objects into a dict:\"\"\"\n",
    "uvds = []\n",
    "for pol in pols:\n",
    "    if pol.lower() in STD_POLS:\n",
    "        uvds.append((pol.lower(), uvds_std_pols[pol.lower()]))\n",
    "\n",
    "    elif pol in pS_POLS:\n",
    "        if pol == 'pI':\n",
    "            uvdI = hp.pstokes.construct_pstokes(dset1=uvds_std_pols['xx'], dset2=uvds_std_pols['yy'], pstokes='pI')\n",
    "            uvds.append((pol, uvdI))\n",
    "        if pol == 'pQ':\n",
    "            uvdQ = hp.pstokes.construct_pstokes(dset1=uvds_std_pols['xx'], dset2=uvds_std_pols['yy'], pstokes='pQ')\n",
    "            uvds.append((pol, uvdQ))\n",
    "        if pol == 'pU':\n",
    "            uvdU = hp.pstokes.construct_pstokes(dset1=uvds_std_pols['xy'], dset2=uvds_std_pols['yx'], pstokes='pU')\n",
    "            uvds.append((pol, uvdU))\n",
    "        if pol == 'pV':\n",
    "            uvdV = hp.pstokes.construct_pstokes(dset1=uvds_std_pols['xy'], dset2=uvds_std_pols['yx'], pstokes='pV')\n",
    "            uvds.append((pol, uvdV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Making UVPspec objects:\"\"\"\n",
    "for pol, uvd in uvds:\n",
    "    # Apply flags\n",
    "    uvd.data_array *= np.logical_not(uvd.flag_array)\n",
    "\n",
    "    # Intialize a cosmology and a beam\n",
    "    if pol in STD_POLS:\n",
    "        beamfile = os.path.join(DATA_PATH, 'HERA_NF_dipole_power.beamfits')\n",
    "    elif pol in pS_POLS:\n",
    "        beamfile = os.path.join(DATA_PATH, 'HERA_NF_pstokes_power.beamfits')\n",
    "    cosmo = hp.conversions.Cosmo_Conversions()\n",
    "    uvb = hp.pspecbeam.PSpecBeamUV(beamfile, cosmo=cosmo)\n",
    "\n",
    "    # Convert to cosmological units (mK)\n",
    "    if ('C' in uvd.extra_keywords['ext']) or ('K' in uvd.extra_keywords['ext']):\n",
    "        Jy_to_mK = uvb.Jy_to_mK(np.unique(uvd.freq_array), pol=pol)\n",
    "        uvd.data_array *= Jy_to_mK[None, None, :, None]\n",
    "\n",
    "    # Shift data and load datasets\n",
    "    uvd1 = uvd.select(times=np.unique(uvd.time_array)[:-1:2], inplace=False)\n",
    "    uvd2 = uvd.select(times=np.unique(uvd.time_array)[1::2], inplace=False)\n",
    "    ds = hp.PSpecData(dsets=[uvd1, uvd2], wgts=[None, None], beam=uvb)\n",
    "\n",
    "    # Set visibility units\n",
    "    if ('C' in uvd.extra_keywords['ext']) or ('K' in uvd.extra_keywords['ext']):\n",
    "        ds.dsets[0].vis_units = 'mK'\n",
    "        ds.dsets[1].vis_units = 'mK'\n",
    "\n",
    "    # Phase data (What does this do?)\n",
    "    ds.rephase_to_dset(0)\n",
    "\n",
    "    \"\"\"Categorize baselines into physical separation length\"\"\"\n",
    "    # Setup norm binning\n",
    "    BIN_WIDTH = 0.3\n",
    "    NORM_BINS = np.arange(0.0, 10000.0, BIN_WIDTH)\n",
    "\n",
    "    # Retrieve antenna positions in a dictionary\n",
    "    antpos = {ant: pos for ant, pos in zip(uvd.get_ENU_antpos()[1], uvd.get_ENU_antpos()[0])}\n",
    "\n",
    "    # Retrieve antenna pairs and bad antennae\n",
    "    antpairs = uvd.get_antpairs()\n",
    "    xants = uvd.extra_keywords['xants']\n",
    "\n",
    "    # Sort antenna pairs by their physical separation\n",
    "    blpairs, blp_reds = [], {}\n",
    "    baselines, bls_reds = [], {}\n",
    "    norms = []\n",
    "    for antpair in antpairs:\n",
    "        ant0, ant1 = antpair\n",
    "        if (ant0 in xants) or (ant1 in xants) or (ant0 >= ant1):\n",
    "            continue\n",
    "        baselines.append(antpair)\n",
    "        blpair = (antpair, antpair)\n",
    "        blpairs.append(blpair)\n",
    "        norm = np.linalg.norm(antpos[ant0] - antpos[ant1])\n",
    "        norm = np.round(np.digitize(norm, NORM_BINS) * BIN_WIDTH, 1)\n",
    "        norms.append(norm)\n",
    "\n",
    "        if norm in bls_reds:\n",
    "            bls_reds[norm].append(antpair)\n",
    "            blp_reds[norm].append(blpair)\n",
    "        else:\n",
    "            bls_reds[norm] = [antpair]\n",
    "            blp_reds[norm] = [blpair]\n",
    "    norms = sorted(np.unique(norms))\n",
    "\n",
    "    \"\"\"Make UVPspec object\"\"\"\n",
    "    uvp = ds.pspec(\n",
    "        baselines,\n",
    "        baselines,\n",
    "        (0, 1),\n",
    "        pols=[(pol, pol)],\n",
    "        spw_ranges=[(FREQrng[0], FREQrng[-1])],\n",
    "        taper=\"blackman-harris\",\n",
    "        verbose=False)\n",
    "\n",
    "    \"\"\"Name and save UVPspec object\"\"\"\n",
    "    hdf5 = 'zen.{JD}.{JDt0}_{JDtf}.{pol}.HH.hdf5.{ext}.UVP'.format(\n",
    "        JD=uvd.extra_keywords['JD'],\n",
    "        JDt0=uvd.extra_keywords['JDt0'],\n",
    "        JDtf=uvd.extra_keywords['JDtf'],\n",
    "        pol=pol,\n",
    "        ext=uvd.extra_keywords['ext'])\n",
    "    hdf5 = os.path.join(savepath, hdf5)\n",
    "    print 'Writing:'\n",
    "    print hdf5\n",
    "    uvp.write_hdf5(hdf5, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Saving additional metadata:\"\"\"\n",
    "metadata = os.path.join(savepath, 'metadata.npz')\n",
    "np.savez(\n",
    "    metadata,\n",
    "    uvd_extra_keywords=uvd.extra_keywords,\n",
    "    bls_reds=bls_reds,\n",
    "    blp_reds=blp_reds,\n",
    "    baselines=baselines,\n",
    "    blpairs=blpairs,\n",
    "    norms=norms,\n",
    "    antpos=antpos,\n",
    "    FREQrng=FREQrng)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
