{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This script will convert 4 hdf5 files into N*4 hdf5 files containing \n",
    "UVPspec objects where N is the number of redundnant baseline groups.\"\"\"\n",
    "# Python Standard Library Packages\n",
    "import os\n",
    "# import copy\n",
    "import glob\n",
    "import argparse\n",
    "\n",
    "# Community Developed Packages\n",
    "import numpy as np\n",
    "\n",
    "# HERA Collaboration Packages\n",
    "import hera_pspec as hp\n",
    "from hera_pspec.data import DATA_PATH\n",
    "from pyuvdata import UVData\n",
    "from hera_cal import redcal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-d\",\n",
    "    \"--day\",\n",
    "    help=\"Designate the night of IDR2.1 observation to be analyzed.\",\n",
    "    required=True)\n",
    "parser.add_argument(\"-e\",\n",
    "    \"--ext\",\n",
    "    help=\"Designate the file extension of the files to be analyzed.\",\n",
    "    required=True)\n",
    "parser.add_argument(\"-s\",\n",
    "    \"--spw\",\n",
    "    help=\"Designate the spectral window range in channels (i.e., 0_1023).\",\n",
    "    Nargs=*,\n",
    "    required=True)\n",
    "args = parser.parse_args()\n",
    "DAY = args.day\n",
    "EXT = args.ext\n",
    "SPW = [(rng.split('_')[0], rng.split('_')[1]) for rng in args.spw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = '2458111'\n",
    "EXT = 'uvOCRSD'\n",
    "SPW = [(580, 680)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to hdf5 files\n",
    "hdf5_DATA_PATH = '/lustre/aoc/projects/hera/afortino/{}/zen_{}_times_1pol_HH_{}_hdf5/'.format(DAY, DAY, EXT)\n",
    "\n",
    "# Retrieves hdf5 files\n",
    "FILE_SKELETON = '*{}*{}.hdf5'.format(DAY, EXT)\n",
    "FILE_SKELETON = os.path.join(hdf5_DATA_PATH, FILE_SKELETON)\n",
    "hdf5_FILES = np.array(sorted(glob.glob(FILE_SKELETON)))\n",
    "\n",
    "# Saves new hdf5 files\n",
    "SAVE_PATH = '/lustre/aoc/projects/hera/afortino/{}/zen_{}_times_1pol_PS_{}_hdf5/'.format(DAY, DAY, EXT)\n",
    "os.system('mkdir -p {}'.format(SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dfile in hdf5_FILES:\n",
    "    print 'Reading: {}'.format(dfile)\n",
    "    \n",
    "    # Initialize UVData object to read and contain MIRIAD information\n",
    "    uvd = UVData()\n",
    "    uvd.read_uvh5(dfile)\n",
    "    pol = uvd.get_pols()[0].lower()\n",
    "\n",
    "    # Apply flags\n",
    "    uvd.data_array *= np.logical_not(uvd.flag_array)\n",
    "\n",
    "    # Intialize a cosmology and a beam\n",
    "    cosmo = hp.conversions.Cosmo_Conversions()\n",
    "    beamfile = os.path.join(DATA_PATH, 'NF_HERA_Beams.beamfits')\n",
    "    uvb = hp.pspecbeam.PSpecBeamUV(beamfile, cosmo=cosmo)\n",
    "\n",
    "    # Convert to cosmological units (mK)\n",
    "    Jy_to_mK = uvb.Jy_to_mK(np.unique(uvd.freq_array), pol=\"xx\")\n",
    "    uvd.data_array *= Jy_to_mK[None, None, :, None]\n",
    "\n",
    "    # Shift data and load datasets\n",
    "    uvd1 = uvd.select(times=np.unique(uvd.time_array)[:-1:2], inplace=False)\n",
    "    uvd2 = uvd.select(times=np.unique(uvd.time_array)[1::2], inplace=False)\n",
    "    ds = hp.PSpecData(dsets=[uvd1, uvd2], wgts=[None, None], beam=uvb)\n",
    "\n",
    "    # Set visibility units\n",
    "    ds.dsets[0].vis_units = 'mK'\n",
    "    ds.dsets[1].vis_units = 'mK'\n",
    "    \n",
    "    # Phase data (What does this do?)\n",
    "    ds.rephase_to_dset(0)\n",
    "    \n",
    "    \"\"\"Categorize baselines into physical separation length\"\"\"\n",
    "    # Setup norm binning\n",
    "    BIN_WIDTH = 0.3\n",
    "    NORM_BINS = np.arange(0.0, 10000.0, BIN_WIDTH)\n",
    "\n",
    "    # Retrieve antenna positions in a dictionary\n",
    "    antpos = {ant: pos for ant, pos in zip(uvd.get_ENU_antpos()[1], uvd.get_ENU_antpos()[0])}\n",
    "\n",
    "    # Retrieve antenna pairs and bad antennae\n",
    "    antpairs = uvd.get_antpairs()\n",
    "    xants1, xants2 = hp.utils.calc_reds(uvd1, uvd2)[3:]\n",
    "    xants = np.unique(xants1 + xants2)\n",
    "\n",
    "    # Sort antenna pairs by their physical separation\n",
    "    reds = {}\n",
    "    for antpair in antpairs:\n",
    "        ant0, ant1 = antpair\n",
    "        if (ant0 in xants) or (ant1 in xants) or (ant0 >= ant1):\n",
    "            continue\n",
    "        norm = np.linalg.norm(antpos[ant0] - antpos[ant1])\n",
    "        norm = np.round(np.digitize(norm, NORM_BINS) * BIN_WIDTH, 1)\n",
    "\n",
    "        if norm in reds:\n",
    "            reds[norm].append(antpair)\n",
    "        else:\n",
    "            reds[norm] = [antpair]\n",
    "    norms = sorted(reds.keys())\n",
    "    \n",
    "    \"\"\"Make UVPspec objects for each baseline bin\"\"\"\n",
    "    for norm in norms:\n",
    "        print 'Making Power Spectrum for baseline group {}m'.format(norm)\n",
    "        uvp = ds.pspec(\n",
    "            reds[norm],\n",
    "            reds[norm],\n",
    "            (0, 1),\n",
    "            pols=(pol, pol),\n",
    "            spw_ranges=SPW,\n",
    "            taper=\"blackman-harris\",\n",
    "            verbose=False)\n",
    "        hdf5 = '{}m.{}.hdf5'.format(norm, pol)\n",
    "        hdf5 = os.path.join(SAVE_PATH, hdf5)\n",
    "        uvp.write_hdf5(hdf5, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JDt0 = uvd.extra_keywords['JDt0']\n",
    "JDtf = uvd.extra_keywords['JDtf']\n",
    "JD = uvd.extra_keywords['JD']\n",
    "numfiles = uvd.extra_keywords['numfiles']\n",
    "EXT = uvd.extra_keywords['ext']\n",
    "\n",
    "metadata = os.path.join(SAVE_PATH, 'metadata.npz')\n",
    "np.savez(\n",
    "    metadata,\n",
    "    JDt0=JDt0,\n",
    "    JDtf=JDtf,\n",
    "    JD=JD,\n",
    "    numfiles=numfiles,\n",
    "    EXT=EXT,\n",
    "    reds=reds,\n",
    "    norms=norms,\n",
    "    antpos=antpos,\n",
    "    xants=xants)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
