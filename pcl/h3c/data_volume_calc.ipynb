{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy import units\n",
    "from astropy.coordinates import Angle\n",
    "\n",
    "from bda import decorr_calc as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define correlator specifics\n",
    "max_decorr = 0.1  # acceptable decorrelation fraction\n",
    "freq = 250 * units.MHz\n",
    "corr_FoV_angle = Angle(20.0 * units.deg)\n",
    "chan_width = (250 * units.MHz / 8192)  # 250 MHz bandwidth over 8192 channels\n",
    "pre_fs_int_time = 0.1 * units.s  # 100 ms fringe stopping inside correlator\n",
    "corr_int_time = 2 * units.s  # default correlator integration time\n",
    "max_int_time = 16 * units.s  # maximum integration time permitted\n",
    "\n",
    "# figure out maximum number of samples to average\n",
    "max_samples = (max_int_time / corr_int_time).to(units.dimensionless_unscaled)\n",
    "max_two_foldings = int(np.floor(np.log2(max_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3c_ants_fn = \"/Users/plaplant/Documents/school/penn/software/ProjectFiles/spec_calcs/h2c/hera_350.dat\"\n",
    "ant_names = np.loadtxt(h3c_ants_fn, usecols=(0,), dtype=str)\n",
    "ant_nums = np.array([int(ant_name[2:]) for ant_name in ant_names])\n",
    "ant_pos = np.loadtxt(h3c_ants_fn, usecols=(1, 2, 3))\n",
    "\n",
    "# antennas positions are technically eastings/northings, but close enough to treat as ENU\n",
    "N_ants = len(ant_nums)\n",
    "num_baselines = int(N_ants * (N_ants + 1) / 2)\n",
    "ant_1_array = np.zeros((num_baselines,), dtype=np.int)\n",
    "ant_2_array = np.zeros((num_baselines,), dtype=np.int)\n",
    "uvw_array = np.zeros((num_baselines, 3))\n",
    "bda_compression = np.zeros((num_baselines,))\n",
    "bl = 0\n",
    "for i in range(N_ants):\n",
    "    for j in range(i, N_ants):\n",
    "        ant_1_array[bl] = i\n",
    "        ant_2_array[bl] = j\n",
    "        uvw_array[bl, :] = ant_pos[i, :] - ant_pos[j, :]\n",
    "\n",
    "        # compute expected decorr\n",
    "        lx = np.abs(uvw_array[bl, 0]) * units.m\n",
    "        ly = np.abs(uvw_array[bl, 1]) * units.m\n",
    "\n",
    "        if i == j:\n",
    "            # autocorrelation\n",
    "            n_two_foldings = 0\n",
    "        else:\n",
    "            # figure out BDA factor\n",
    "            n_two_foldings = dc.bda_compression_factor(\n",
    "                max_decorr,\n",
    "                freq,\n",
    "                lx,\n",
    "                ly,\n",
    "                corr_FoV_angle,\n",
    "                chan_width,\n",
    "                pre_fs_int_time,\n",
    "                corr_int_time\n",
    "            )\n",
    "        n_two_foldings = min(n_two_foldings, max_two_foldings)\n",
    "\n",
    "        # save result in array\n",
    "        bda_compression[bl] = 2**(-n_two_foldings)\n",
    "\n",
    "        # increment baseline number\n",
    "        bl += 1\n",
    "\n",
    "# define default parameters\n",
    "nchans_default = 6144\n",
    "npols_default = 4\n",
    "hours_default = 12\n",
    "\n",
    "base_compression = np.sum(bda_compression)\n",
    "base_volume = 60 * units.TB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation Options\n",
    "Change the options below to understand the impact on resulting data volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general observing options\n",
    "nchans_to_keep = 6144\n",
    "npols_to_keep = 4\n",
    "hours_to_keep = 12\n",
    "keep_diffs = True\n",
    "\n",
    "# BDA options\n",
    "decorr_level = 0.1\n",
    "decorr_FoV_angle = Angle(20.0 * units.deg)\n",
    "aggressive_int_time = 16 * units.s\n",
    "max_samples = (aggressive_int_time / corr_int_time).to(units.dimensionless_unscaled)\n",
    "max_two_foldings = int(np.floor(np.log2(max_samples)))\n",
    "\n",
    "# baseline cut options\n",
    "bl_len_min = 0.0 * units.m\n",
    "bl_len_max = 1 * units.km\n",
    "\n",
    "# figure out which baselines to keep\n",
    "bls_kept = np.ones_like(bda_compression, dtype=np.bool)\n",
    "\n",
    "for i, comp_factor in enumerate(bda_compression):\n",
    "    # see if bl length is in range\n",
    "    bl_len = np.linalg.norm(uvw_array[i, :]) * units.m\n",
    "    if bl_len < bl_len_min or bl_len > bl_len_max:\n",
    "        bls_kept[i] = False\n",
    "\n",
    "# figure out resulting volume\n",
    "chan_frac = nchans_to_keep / nchans_default\n",
    "pol_frac = npols_to_keep / npols_default\n",
    "time_frac = hours_to_keep / hours_default\n",
    "\n",
    "chan_width /= chan_frac\n",
    "\n",
    "if (decorr_level > max_decorr or decorr_FoV_angle > corr_FoV_angle\n",
    "    or aggressive_int_time > max_int_time):\n",
    "    # we need to recompute the bda_compression factor\n",
    "    new_bda_comprression = np.zeros_like(bda_comprssion)\n",
    "    for bl in range(len(bda_compression)):\n",
    "        if not bls_kept[bl]:\n",
    "            continue\n",
    "        i = ant_1_array[bl]\n",
    "        j = ant_2_array[bl]\n",
    "        lx = uvw_array[bl, 0] * units.m\n",
    "        ly = uvw_array[bl, 1] * units.m\n",
    "        if i == j:\n",
    "            n_two_foldings = 0\n",
    "        else:\n",
    "            # figure out BDA factor\n",
    "            n_two_foldings = dc.bda_compression_factor(\n",
    "                decorr_level,\n",
    "                freq,\n",
    "                lx,\n",
    "                ly,\n",
    "                decorr_FoV_angle,\n",
    "                chan_width,\n",
    "                pre_fs_int_time,\n",
    "                corr_int_time\n",
    "            )\n",
    "        n_two_foldings = min(n_two_foldings, max_two_foldings)\n",
    "        \n",
    "        # save result in array\n",
    "        bda_compression[bl] = 2**(-n_two_foldings)\n",
    "else:\n",
    "    new_bda_compression = bda_compression\n",
    "    \n",
    "masked_bda = np.ma.masked_array(new_bda_compression, mask=~bls_kept)\n",
    "bda_frac = np.ma.sum(masked_bda) / np.sum(bda_compression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New nightly data volume: \n",
      "60.0 Tbyte\n"
     ]
    }
   ],
   "source": [
    "# Grand total\n",
    "reduction_frac = 1 * chan_frac * pol_frac * time_frac * bda_frac\n",
    "if not keep_diffs:\n",
    "    reduction_frac *= 0.5\n",
    "\n",
    "print(\"New nightly data volume: \")\n",
    "print(reduction_frac * base_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hera3]",
   "language": "python",
   "name": "conda-env-hera3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
