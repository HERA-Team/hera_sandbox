{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function, division, absolute_import\n",
    "import numpy as np\n",
    "from astropy import constants as const\n",
    "from astropy.coordinates import Angle\n",
    "from astropy import units\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants\n",
    "frequency = (250 * 1e6 * units.Hz)\n",
    "wavelength = const.c / frequency.to(1/units.s)\n",
    "earth_rot_speed = (Angle(360, units.deg) / units.sday).to(units.rad/units.s)\n",
    "corr_FoV_min = Angle(10., units.degree)\n",
    "hera_latitude = Angle('-30:43:17.5', units.deg)\n",
    "corr_int_time = 0.1 * units.s\n",
    "corr_post_fs_int_time = 10. * units.s\n",
    "n_channels = 8192\n",
    "corr_chan_width = (250 * units.MHz) / n_channels\n",
    "max_decorr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bl_resolution(bl_len):\n",
    "    # baseline angular resolution\n",
    "    return Angle(np.arcsin(min(1, wavelength/(np.max(bl_len, 0.1*units.m)))), units.radian).to(units.arcminute)\n",
    "\n",
    "def decorr_int_time(lx, ly):\n",
    "    # decorrelation due to pre-fringe-stopped integration time\n",
    "    x_res = bl_resolution(lx)\n",
    "    y_res = bl_resolution(ly)\n",
    "    dit_x = corr_int_time * earth_rot_speed / x_res.to(units.arcminute)\n",
    "    dit_y = corr_int_time * earth_rot_speed * np.abs(np.sin(hera_latitude)) / y_res.to(units.arcminute)\n",
    "    dit = max(dit_x, dit_y)\n",
    "    return dit.value\n",
    "\n",
    "def decorr_chan_width(bl_len):\n",
    "    # decorrelation due to channel width\n",
    "    dcw = (corr_chan_width.to(1/units.s) * bl_len * units.m\n",
    "           * np.sin(corr_FoV_min.to(units.rad)) / const.c)\n",
    "    return dcw.value\n",
    "\n",
    "def decorr_pre_fs(lx, ly, bl_len):\n",
    "    # decorrelation from pre-fringe-stopped considerations (integration time + channel width)\n",
    "    dit = decorr_int_time(lx, ly)\n",
    "    return 1 - (1 - dit) * (1 - decorr_chan_width(bl_len))\n",
    "\n",
    "def dudt(lx, ly, ha):\n",
    "    \"\"\"\n",
    "    Define partial u/ partial t from Eqn. 42 in Wijnholds et al. 2018\n",
    "\n",
    "    Assumes that lx, ly are in units of meters.\n",
    "    \"\"\"\n",
    "    return (lx * np.cos(ha) - ly * np.sin(ha)) * earth_rot_speed / wavelength\n",
    "\n",
    "def dvdt(lx, ly, ha, dec):\n",
    "    \"\"\"\n",
    "    Define partial v/ partial t from Eqn. 42 in Wijnholds et al. 2018\n",
    "\n",
    "    Assumes that lx, ly are in units of meters.\n",
    "    \"\"\"\n",
    "    return (lx * np.sin(dec) * np.sin(ha) + ly * np.sin(dec) * np.cos(ha)) * earth_rot_speed / wavelength\n",
    "\n",
    "def decorr_post_fs_int_time(lx, ly, int_time):\n",
    "    # find the maximum decorrelation for the source 10 degrees off zenith in +/- l and +/- m\n",
    "\n",
    "    # case 1: +l\n",
    "    du = dudt(lx, ly, corr_FoV_min)\n",
    "    dv = dvdt(lx, ly, corr_FoV_min, hera_latitude)\n",
    "    l = np.cos(90*units.deg + corr_FoV_min)\n",
    "    m = 0.\n",
    "    rfac = (du * l + dv * m)**2\n",
    "    \n",
    "    # case 2: -l\n",
    "    du = dudt(lx, ly, -corr_FoV_min)\n",
    "    dv = dvdt(lx, ly, corr_FoV_min, hera_latitude)\n",
    "    l = np.cos(90*units.deg - corr_FoV_min)\n",
    "    m = 0.\n",
    "    rfac = max(rfac, (du * l + dv * m)**2)\n",
    "    \n",
    "    # case 3: +m\n",
    "    du = dudt(lx, ly, 0.)\n",
    "    dv = dvdt(lx, ly, 0., hera_latitude + corr_FoV_min)\n",
    "    l = 0.\n",
    "    m = np.cos(90*units.deg + corr_FoV_min)\n",
    "    rfac = max(rfac, (du * l + dv * m)**2)\n",
    "    \n",
    "    # case 4: -m\n",
    "    du = dudt(lx, ly, 0.)\n",
    "    dv = dvdt(lx, ly, 0., hera_latitude - corr_FoV_min)\n",
    "    l = 0.\n",
    "    m = np.cos(90*units.deg - corr_FoV_min)\n",
    "    rfac = max(rfac, (du * l + dv * m)**2)\n",
    "\n",
    "    # add to other factors\n",
    "    return np.pi**2 * int_time.value**2 / 6. * rfac.value\n",
    "\n",
    "def decorr_total(lx, ly, bl_len, int_time):\n",
    "    return 1 - (1 - decorr_pre_fs(lx, ly, bl_len)) * (1 - decorr_post_fs_int_time(lx, ly, int_time))\n",
    "\n",
    "def fs_int_time(lx, ly, decorr_val):\n",
    "    # fringe-stopped integration time for a given baseline separation and decorrelation value\n",
    "\n",
    "    # case 1: +l\n",
    "    du = dudt(lx, ly, corr_FoV_min)\n",
    "    dv = dvdt(lx, ly, corr_FoV_min, hera_latitude)\n",
    "    l = np.cos(90*units.deg + corr_FoV_min)\n",
    "    m = 0.\n",
    "    rfac = (du * l + dv * m)**2\n",
    "    \n",
    "    # case 2: -l\n",
    "    du = dudt(lx, ly, -corr_FoV_min)\n",
    "    dv = dvdt(lx, ly, corr_FoV_min, hera_latitude)\n",
    "    l = np.cos(90*units.deg - corr_FoV_min)\n",
    "    m = 0.\n",
    "    rfac = max(rfac, (du * l + dv * m)**2)\n",
    "    \n",
    "    # case 3: +m\n",
    "    du = dudt(lx, ly, 0.)\n",
    "    dv = dvdt(lx, ly, 0., hera_latitude + corr_FoV_min)\n",
    "    l = 0.\n",
    "    m = np.cos(90*units.deg + corr_FoV_min)\n",
    "    rfac = max(rfac, (du * l + dv * m)**2)\n",
    "    \n",
    "    # case 4: -m\n",
    "    du = dudt(lx, ly, 0.)\n",
    "    dv = dvdt(lx, ly, 0., hera_latitude - corr_FoV_min)\n",
    "    l = 0.\n",
    "    m = np.cos(90*units.deg - corr_FoV_min)\n",
    "    rfac = max(rfac, (du * l + dv * m)**2)\n",
    "\n",
    "    # invert to get integration time\n",
    "    return np.sqrt(6 * decorr_val / (np.pi**2 * rfac.value))\n",
    "\n",
    "def max_int_time(lx, ly, bl_len, max_decorr):\n",
    "    # Compute the maximum post-fring-stopped integration time for a given baseline\n",
    "    # length, in m, and max decorrelation fraction\n",
    "    # Assumes fringe stopping\n",
    "    dpf = decorr_pre_fs(lx, ly, bl_len)\n",
    "    dfs = 1 - (1 - max_decorr)/(1 - dpf)\n",
    "    int_time = fs_int_time(lx, ly, dfs)\n",
    "\n",
    "    return int_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hera_txt = '/Users/plaplant/Documents/school/penn/software/hera_mc/hera_mc/data/HERA_350.txt'\n",
    "hera_bls = np.genfromtxt(hera_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decorr_total:  0.0286371700403\n",
      "new_int_time:  25.2646734331\n",
      "ratio:  2.52646734331\n",
      "fac:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/plaplant/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.py:26: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/Users/plaplant/anaconda2/lib/python2.7/site-packages/astropy/units/quantity.py:1059: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return super(Quantity, self).__truediv__(other)\n"
     ]
    }
   ],
   "source": [
    "lx = 870 * units.m\n",
    "ly = 0. * units.m\n",
    "length = np.sqrt(lx**2 + ly**2)\n",
    "dt = decorr_total(lx, ly, length, corr_post_fs_int_time)\n",
    "nit = max_int_time(lx, ly, length, 0.1)\n",
    "r = nit / corr_post_fs_int_time.value\n",
    "fac = np.floor(np.log2(r))\n",
    "print(\"decorr_total: \", dt)\n",
    "print(\"new_int_time: \", nit)\n",
    "print(\"ratio: \", r)\n",
    "print(\"fac: \", fac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the savings for each baseline in the array\n",
    "# XXX: takes ~5 minutes; might be able to be more clever, but easier to shut up and calculate\n",
    "max_bda_comp_factor = 0.\n",
    "simple_bda_comp_factor = 0.\n",
    "\n",
    "nants = hera_bls.shape[0]\n",
    "for iant in range(nants):\n",
    "    # first column is antenna name; second--fourth columns are xyz positions, in meters\n",
    "    xi = hera_bls[iant, 1]\n",
    "    yi = hera_bls[iant, 2]\n",
    "    for jant in range(iant + 1, nants):\n",
    "        xj = hera_bls[jant, 1]\n",
    "        yj = hera_bls[jant, 2]\n",
    "\n",
    "        # assume EW separation is Delta(x) and NS separation is Delta(y)--true-ish to 1st order\n",
    "        lx = np.abs(xi - xj) * units.m\n",
    "        ly = np.abs(yi - yj) * units.m\n",
    "        \n",
    "        # get total length\n",
    "        length = np.sqrt(lx**2 + ly**2)\n",
    "        \n",
    "        # compute max decorrelation value along principal axes\n",
    "        dt = decorr_total(lx, ly, length, corr_post_fs_int_time)\n",
    "\n",
    "        if dt < max_decorr:\n",
    "            # we can theoretically integrate this bl in time until we hit the max_decorr\n",
    "            new_int_time = max_int_time(lx, ly, length, max_decorr)\n",
    "            max_bda_comp_factor += corr_post_fs_int_time.value / new_int_time\n",
    "\n",
    "            # also compute the max power-of-two integration factor\n",
    "            fac = np.floor(np.log2(new_int_time / corr_post_fs_int_time.value))\n",
    "            simple_bda_comp_factor += 2.**(-fac)\n",
    "            \n",
    "            # drive home the point that the default correlator output rates are overkill for most baselines\n",
    "            if fac == 0:\n",
    "                print(\"No compression savings possible for this baseline\")\n",
    "        else:\n",
    "            # no savings\n",
    "            max_bda_comp_factor += 1\n",
    "            simple_bda_comp_factor += 1\n",
    "\n",
    "# add factor for autos; assume no compression\n",
    "# note that it doesn't really matter what we put, since these are < 1% of baselines\n",
    "max_bda_comp_factor += nants\n",
    "simple_bda_comp_factor += nants\n",
    "\n",
    "# normalize by the number of baselines\n",
    "nbls = (nants * (nants + 1)) / 2\n",
    "max_bda_comp_factor /= nbls\n",
    "simple_bda_comp_factor /= nbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretic maximum baseline-dependent averaging compression factor for HERA-350 array: \n",
      "0.0641460074895 \n",
      "\n",
      "Power-of-2 compression factor: \n",
      "0.0897276912902\n"
     ]
    }
   ],
   "source": [
    "print(\"Theoretic maximum baseline-dependent averaging compression factor for HERA-350 array: \")\n",
    "print(max_bda_comp_factor, \"\\n\")\n",
    "print(\"Power-of-2 compression factor: \")\n",
    "print(simple_bda_comp_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive data rate:       2.41532928 Gbyte / s\n",
      "Naive season volume:   12.5210669875 Pbyte \n",
      "\n",
      "BDA data rate:         0.21672192 Gbyte / s\n",
      "BDA season volume:     1.12348643328 Pbyte\n"
     ]
    }
   ],
   "source": [
    "# compute data rate for season\n",
    "channels_to_keep = n_channels * 3. / 4.\n",
    "sum_diff_factor = 2\n",
    "bytes_per_vis = 8 * units.byte\n",
    "n_polarizations = 4\n",
    "obs_hrs_per_day = 12 * units.hour / units.day\n",
    "days_per_season = 120 * units.day\n",
    "\n",
    "naive_data_rate = (channels_to_keep * nbls * n_polarizations * bytes_per_vis\n",
    "                   * sum_diff_factor / corr_post_fs_int_time)\n",
    "naive_data_vol = naive_data_rate * obs_hrs_per_day * days_per_season\n",
    "bda_data_rate = simple_bda_comp_factor * naive_data_rate\n",
    "bda_data_vol = bda_data_rate * obs_hrs_per_day * days_per_season\n",
    "print(\"Naive data rate:      \", naive_data_rate.to(units.Gbyte/units.s))\n",
    "print(\"Naive season volume:  \", naive_data_vol.to(units.Pbyte), \"\\n\")\n",
    "print(\"BDA data rate:        \", bda_data_rate.to(units.Gbyte/units.s))\n",
    "print(\"BDA season volume:    \", bda_data_vol.to(units.Pbyte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
