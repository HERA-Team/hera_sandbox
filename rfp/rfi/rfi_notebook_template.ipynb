{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\nants}{N_{ants}}\n",
    "\\newcommand{\\npols}{N_{pols}}\n",
    "\\newcommand{\\nfreqs}{N_{freqs}}\n",
    "\\newcommand{\\ntimes}{N_{times}}\n",
    "$$\n",
    "The purpose of this notebook is to provide a template for visualizing RFI from narrowband transmitters. It works by searching for a particular file within the current working directory, loading that file, then performing a standard analysis on the data and plotting the results. For an array with $\\nants$ antennas and $\\npols$ visibility polarizations, which measures $\\ntimes$ integrations per night using a correlator with $\\nfreqs$ frequency channels, the data hypercube for a single night has shape $(\\nants(\\nants+1)^2/2, \\ntimes, \\nfreqs, \\npols)$, or some reshaping thereof.  The analysis is currently performed only on autocorrelations and linear polarizations, so the data cubes used in this analysis have shape $(\\nants, \\ntimes, \\nfreqs, 2)$. Since plots tend to become overwhelming when we try to include more than two independent axes, we must work with various projections or summary statistics that reduce the dimensionality of the data when visualizing the results for the entire array. This notebook serves to provide some of the most useful plots for understanding narrowband RFI&mdash;that is, RFI that is persistent and confined to a small range of frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy import units\n",
    "\n",
    "import uvtools\n",
    "from pyuvdata import UVData\n",
    "from hera_mc import cm_hookup\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ant_to_node_map():\n",
    "    \"\"\"Get a dictionary mapping antenna numbers to node numbers.\"\"\"\n",
    "    \n",
    "    # load in the hookup information for HERA, as of now\n",
    "    db_hookup = cm_hookup.Hookup()\n",
    "    \n",
    "    # take only the antenna/node information from the hookup table\n",
    "    hookup_dict = db_hookup.get_hookup(\"HH\")\n",
    "    ant_to_node_table = db_hookup.show_hookup(\n",
    "        hookup_dict, cols_to_show=(\"antenna\", \"node\")\n",
    "    )\n",
    "    \n",
    "    # use regular expressions to pull the antenna/node numbers\n",
    "    ant_pattern = re.compile(\"A[0-9]+\")\n",
    "    node_pattern = re.compile(\"N[0-9]+\")\n",
    "    ants = ant_pattern.findall(ant_to_node_table)\n",
    "    nodes = node_pattern.findall(ant_to_node_table)\n",
    "\n",
    "    # convert the antennas/nodes to integers (for simplifying their use)\n",
    "    ants = [int(ant[1:]) for ant in ants] # remove the leading A\n",
    "    nodes = [int(node[1:]) for node in nodes] # remove the leading N\n",
    "    \n",
    "    # return the ant : node mapping\n",
    "    return dict(zip(ants, nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_channelized_data(data, data_bounds=None, figsize=None,\n",
    "                          nrows=None, ncols=None, pols=None, \n",
    "                          xlabel=None, ylabel=None, extent=None,\n",
    "                          xvals=None, yvals=None,\n",
    "                          xticklabels=None, yticklabels=None,\n",
    "                          cbar_labels=None, cmaps=None,\n",
    "                          gridspec_kws=None):\n",
    "    \"\"\"Plot data that is channelized along one or two axes.\n",
    "    \n",
    "    This function generates a figure following a particular format: \n",
    "    Each row of plots corresponds to a different quantity.\n",
    "    Each column of plots corresponds to a different polarization.\n",
    "    One colorbar is used per row.\n",
    "    \"\"\"\n",
    "    # some setup stuff\n",
    "    if type(data) is np.ndarray:\n",
    "        data = (data,)\n",
    "    data = (np.atleast_3d(data_) for data_ in data)\n",
    "    \n",
    "    nrows = nrows or len(data)\n",
    "    ncols = ncols or data[0].shape[-1]\n",
    "    data_bounds = data_bounds or ((None,) * ncols,) * nrows\n",
    "    \n",
    "    figsize = figsize or (15 * ncols, 10 * nrows)\n",
    "    gridspec_kws = gridspec_kws or {}\n",
    "    \n",
    "    cbar_labels = cbar_labels or (None,) * nrows\n",
    "    cmaps = cmaps or (\"inferno\",) * nrows\n",
    "    if extent is None:\n",
    "        if xvals is not None:\n",
    "            x_extent = (xvals[0], xvals[-1])\n",
    "        else:\n",
    "            x_extent = (0, len(xticklabels))\n",
    "        if yvals is not None:\n",
    "            y_extent = (yvals[-1], yvals[0])\n",
    "        else:\n",
    "            y_extent = (len(yticklabels), 0)\n",
    "        extent = x_extent + y_extent\n",
    "        \n",
    "    # create the figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    axes = fig.subplots(nrows, ncols, gridspec_kw=gridspec_kws)\n",
    "    if axes.ndim == 1:\n",
    "        axes = np.asarray([axes])\n",
    "        # get the orientation right\n",
    "        axes = axes.T if ncols == 1 else axes\n",
    "    \n",
    "    # actually plot stuff\n",
    "    for count, ax in enumerate(axes.ravel()):\n",
    "        rownum = count // ncol\n",
    "        colnum = count % ncol\n",
    "        \n",
    "        # note the polarizations\n",
    "        if rownum == 0:\n",
    "            title = pols[colnum] or \"%s Polarization\" % pols[colnum]\n",
    "            ax.set_title(title, fontsize=12)\n",
    "        \n",
    "        # add labels where appropriate\n",
    "        if rownum == nrows - 1:\n",
    "            ax.set_xlabel(xlabel, fontsize=12)\n",
    "        if colnum == 0:\n",
    "            ax.set_ylabel(ylabel, fontsize=12)\n",
    "            \n",
    "        # prepare data and colormap\n",
    "        use_data = data[rownum][:, :, colnum]\n",
    "        vmin, vmax = data_bounds[rownum]\n",
    "        cmap = cmaps[rownum]\n",
    "        \n",
    "        # actually plot it\n",
    "        cax = ax.imshow(\n",
    "            use_data, aspect='auto', extent=extent, \n",
    "            cmap=cmap, vmin=vmin, vmax=vmax, \n",
    "        )\n",
    "        \n",
    "        # label channels for any channelized axes\n",
    "        if xticklabels:\n",
    "            xticks = np.arange(len(xticklabels)) + 0.5\n",
    "            ax.set_xticks(xticks)\n",
    "            ax.set_xticklabels(xticklabels, rotation='vertical')\n",
    "        if yticklabels:\n",
    "            yticks = np.arange(len(yticklabels)) + 0.5\n",
    "            ax.set_yticks(yticks)\n",
    "            ax.set_yticklabels(yticklabels)\n",
    "            \n",
    "        # add a colorbar after finishing a row\n",
    "        if colnum == ncols - 1:\n",
    "            cbar = fig.colorbar(cax, ax=axes[rownum], pad=0.01)\n",
    "            cbar.set_label(cbar_label, fontsize=12)\n",
    "            \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "PipelineError",
     "evalue": "Environment not correctly configured; could not find either data path or JD.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-ee7f4f41d845>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# follow Lindsay's example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DATA_PATH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mjd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'JULIANDATE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/narrowband_script/lib/python3.7/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'DATA_PATH'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPipelineError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-ee7f4f41d845>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Summary file does not exist in {data_dir}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mPipelineError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mPipelineError\u001b[0m: Environment not correctly configured; could not find either data path or JD."
     ]
    }
   ],
   "source": [
    "# summary file from night of observing will use the following naming convention:\n",
    "# zen.<jd>.rfi_stations.uvh5\n",
    "# where <jd> is the Julian Date of the observation\n",
    "\n",
    "class PipelineError(Exception):\n",
    "    pass\n",
    "\n",
    "# pull the information for finding the file\n",
    "try:\n",
    "    # follow Lindsay's example\n",
    "    dpath = os.environ['DATA_PATH']\n",
    "    jd = os.environ['JULIANDATE']\n",
    "    \n",
    "    # check that the file exists\n",
    "    filename = os.path.join(dpath, \"zen.{jd}.rfi_stations.uvh5\".format(jd=jd))\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError\n",
    "except (KeyError, FileNotFoundError) as err:\n",
    "    # something broke, so find out what went wrong and report it\n",
    "    if type(err) is KeyError:\n",
    "        msg = \"Environment not correctly configured; could not find either data path or JD.\"\n",
    "    else:\n",
    "        msg = \"Summary file does not exist in {data_dir}.\".format(data_dir=dpath)\n",
    "    raise PipelineError(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "UVData.read_uvh5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming all is well, load in the data\n",
    "uvd = UVData()\n",
    "uvd.read_uvh5(filename, ant_str='auto')\n",
    "\n",
    "# pull the metadata and make the data cube \n",
    "freqs = uvd.freq_array.flatten()\n",
    "freqs_MHz = freqs / 1e6\n",
    "\n",
    "lsts = np.unique(uvd.lst_array)\n",
    "lsts_hr = lsts * units.sday.to('hr') / (2 * np.pi)\n",
    "\n",
    "times = np.unique(uvd.time_array)\n",
    "plot_times = times - np.floor(times[0])\n",
    "\n",
    "ants_to_nodes = get_ant_to_node_map()\n",
    "ants = uvd.antenna_numbers\n",
    "antpairs = uvd.get_antpairs()\n",
    "antpairpols = uvd.get_antpairpols()\n",
    "pols = uvd.get_pols()\n",
    "\n",
    "Nants = uvd.Nants\n",
    "Nfreqs = uvd.Nfreqs\n",
    "Ntimes = uvd.Nfreqs\n",
    "Npols = uvd.Npols\n",
    "Nantpols = Nants * Npols\n",
    "\n",
    "vis_data_cube = np.zeros(\n",
    "    (Nants, Ntimes, Nfreqs, Npols), \n",
    "    dtype=np.float\n",
    ")\n",
    "\n",
    "for i, antpair in enumerate(antpairs):\n",
    "    for j, pol in enumerate(pols):\n",
    "        antpairpol = antpair + (pol,)\n",
    "        vis_data_cube[i, :, :, j] = np.abs(uvd.get_data(antpairpol))\n",
    "        \n",
    "# we'll be using lots of log scales, so make sure there are no zeros in the data\n",
    "vis_data_cube[vis_data_cube == 0] = 1\n",
    "\n",
    "# get the flags from the data cube\n",
    "rfi_flags = np.where(vis_data_cube > 1, True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate some different quantities that will be useful. More quantities may be added to this collection later, but for the time being we'll be looking at:\n",
    "* Transmitter duty cycles (how often the transmitter is on) on a per-antpol basis\n",
    "* Time-averaged (mean) transmitter strengths on a per-antpol basis\n",
    "* Transmitter time series (median over antennas) on a per-pol basis\n",
    "* Transmitter signal amplitudes (maximum over time) on a per-antpol basis\n",
    "* Transmitter signal standard deviations over time (only when transmitter is on) on a per-antpol basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how often a given channel is flagged over the course of a night\n",
    "duty_cycles = rfi_flags.mean(axis=1)\n",
    "\n",
    "# impose a cut on duty cycles to identify transmitters; default to 10%\n",
    "duty_cycle_cut = float(os.environ.get('DUTY_CYCLE_CUT', 0.1))\n",
    "has_transmitter = np.where(duty_cycles > duty_cycle_cut, True, False)\n",
    "\n",
    "# do a logical OR over all antpols to find transmitters\n",
    "transmitter_channels = np.where(has_transmitter.sum(axis=0).sum(axis=-1).astype(bool))\n",
    "transmitter_freqs = freqs_MHz[transmitter_channels]\n",
    "transmitter_duty_cycles = duty_cycles[:, transmitter_channels, :]\n",
    "transmitter_data_cube = vis_data_cube[:, :, transmitter_channels, :]\n",
    "\n",
    "# actually compute some things\n",
    "time_averaged_transmitter_data = transmitter_data_cube.mean(axis=1)\n",
    "median_transmitter_time_series = np.median(transmitter_data_cube, axis=0)\n",
    "transmitter_amplitudes = transmitter_data_cube.max(axis=1)\n",
    "transmitter_standard_deviations = np.ones_like(transmitter_amplitudes)\n",
    "for i in range(Nants):\n",
    "    for j in range(transmitter_freqs.size):\n",
    "        for k in range(Npols):\n",
    "            use_data = transmitter_data_cube[i, :, j, k]\n",
    "            # catch cases where an antpol didn't actually observe RFI\n",
    "            # this can either be due to a malfunctioning antenna\n",
    "            # or because the transmitter is internal RFI picked up\n",
    "            # by only a handful of antennas\n",
    "            if use_data[use_data != 1].size <= 1: \n",
    "                continue\n",
    "            # calculate the standard deviation in signal strength\n",
    "            # but *only when the transmitter is on*\n",
    "            transmitter_standard_deviations[i,j,k] = use_data[use_data != 1].std()\n",
    "fractional_transmitter_standard_deviations = transmitter_standard_deviations / transmitter_amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a summary table?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
