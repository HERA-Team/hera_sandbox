{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing 2/3-Compatible Python\n",
    "\n",
    "Written for HERA CHAMP Camp â€” Santa Fe, NM â€” June 14, 2018, by Peter K. G. Williams (peter@newton.cx). Should be generally applicable, though.\n",
    "\n",
    "## Heads up: the `2to3` tool\n",
    "\n",
    "You may have heard that there is a command-line tool, `2to3`, that will edit your code to make it compatible with Python 3. However, it creates code that is **not compatible** with Python 2 anymore. Therefore it doesn't suffice for our purposes. However, it's pretty clever, so when converting existing code it might work well to *start* by running `2to3`, then patching up its edits to match the recommendations below.\n",
    "\n",
    "## Start every file like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Copyright 2018 the HERA Project\n",
    "# Licensed under the 2-clause BSD license (e.g.)\n",
    "\n",
    "\"\"\"Docstring ...\"\"\"\n",
    "\n",
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python 2, this activates three key behaviors that make things compatible with Python 3.\n",
    "\n",
    "To automatically activate this behavior in Jupyter, put the following in `~/.ipython/profile_default/ipython_config.py`:\n",
    "\n",
    "```python\n",
    "c.InteractiveShellApp.exec_lines = [\n",
    "   'from __future__ import absolute_import, division, print_function',\n",
    "]\n",
    "```\n",
    "\n",
    "Note, however, that if you plan on sharing your notebook with other people, they won't necessarily have this configuration set up, so you should explicitly put the `__future__` import at the top of the notebook to ensure that the environment is standardized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print becomes a function\n",
    "\n",
    "You've all heard this. Translating from old `print` to new `print()` is not complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo 123 17\n",
      "incomplete line"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "to a file\n"
     ]
    }
   ],
   "source": [
    "bar = 123\n",
    "print('foo', bar, 17) # the most basic usage is really just a matter of adding parens\n",
    "\n",
    "print('incomplete line', end='') # equivalent to `print 'incomplete_line',`\n",
    "\n",
    "import sys\n",
    "print('to a file', file=sys.stderr) # equivalent to `print >>sys.stderr, 'to a file'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements become absolutely referenced\n",
    "\n",
    "Say that you have a package with a structure like this:\n",
    "\n",
    "```\n",
    "hera_foo/\n",
    "   __init__.py\n",
    "   utils.py\n",
    "   science.py\n",
    "   more/\n",
    "      __init__.py\n",
    "      ideas.py\n",
    "```\n",
    "\n",
    "In Python 2, the following statement in `utils.py` would import the sibling module `science.py`:\n",
    "\n",
    "```python\n",
    "import science\n",
    "```\n",
    "\n",
    "In Python 3 and 2/3-compatible Python 3, imports like this are \"absolute\", and Python will insist on interpreting such an import as asking to find a top-level package named `science`. Instead, you must write:\n",
    "\n",
    "```python\n",
    "from . import science\n",
    "```\n",
    "\n",
    "You can also write things like:\n",
    "\n",
    "```python\n",
    "from .science import do_integral\n",
    "```\n",
    "\n",
    "If you have several layers of modules there is a 'dot-dot' notation to go up one level. From the `ideas.py` you could write:\n",
    "\n",
    "```python\n",
    "from .. import utils\n",
    "```\n",
    "\n",
    "Special bonus fun! If you want your Sphinx docs generation to be compatible with both Python 2 and 3, you need to stick a space in the dots somewhere if you have more than three levels of import (e.g. `from ... import`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integer division needs to be made explicit\n",
    "\n",
    "In plain Python 2, `1 / 2` equals zero. In Python 3 and compatible Python 2, `1 / 2` equals 0.5. The special operator `//` explicitly calls out integer division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 // 2 == 0\n",
    "assert 1 / 2 == 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want an operator that is \"integer division with integers, float division otherwise\", use `past.utils.old_div`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deprecated exception syntaxes are gone\n",
    "\n",
    "The newer syntaxes have been supported forever and you should have been using them anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    raise Exception('oh no') # better than `raise Exception, 'oh no'`\n",
    "except Exception as e: # better than `except Exception, e`\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssertionError \n"
     ]
    }
   ],
   "source": [
    "import six, sys # \"six\" is a module that helps you write 2/3-compatible code\n",
    "\n",
    "try:\n",
    "    try:\n",
    "        assert False\n",
    "    except:\n",
    "        etype, evalue, etb = sys.exc_info()\n",
    "        six.reraise(etype, evalue, etb) # replaces `raise etype, evalue, etb`\n",
    "except Exception as e:\n",
    "    print(e.__class__.__name__, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other changes in this general ballpark (e.g. chaining of exceptions) but most of our code doesn't do anything fancier than this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `int` and `long` types are unified\n",
    "\n",
    "Did you even know that `long` was a type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q is an int\n"
     ]
    }
   ],
   "source": [
    "import six # once again, \"six\" helps you write 2/3-compatible code\n",
    "\n",
    "q = 17\n",
    "\n",
    "if isinstance(q, six.integer_types): # replaces `type(q) == int` and variants\n",
    "    print('q is an int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stringy things default to being Unicode\n",
    "\n",
    "This is by far the most intellectually challenging change, but I'm hopeful that it will be relatively straightforward for us to deal with.\n",
    "\n",
    "For what it's worth, Python 2 was really sloppy about the relevant matters, and Python 3 does a much better job of dealing with them. In Python 3 and 2/3-compatible code, you have to be more careful, but the code you write will be more correct. (The difference is often subtle if you mainly read and write English, but not if you mainly read and write Chinese or Sinhala or Thai or Arabic or Devanagari or ...)\n",
    "\n",
    "Anyway. Both Python 2 and Python 3 have two types that you might thinkg of as \"string-like\": \"bytes\" and \"unicode\".\n",
    "\n",
    "A bytes value is an array of binary data. In both versions of Python, you can reliably get bytes by writing something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 4\n",
      "is bytes? True\n"
     ]
    }
   ],
   "source": [
    "import six\n",
    "\n",
    "my_bytes = b'\\xf0\\x9f\\x92\\xa9' # `\\xNN` encodes a byte in hexadecimal\n",
    "print('len:', len(my_bytes))\n",
    "print('is bytes?', isinstance(my_bytes, six.binary_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A unicode value stores some quantity of \"text\" in any language, construed broadly. In both versions of Python, you can reliably get Unicode by writing something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 11\n",
      "is text? True\n"
     ]
    }
   ],
   "source": [
    "import six\n",
    "\n",
    "my_unicode = u'å¤æ± ã‚„è›™é£›ã³è¾¼ã‚€æ°´ã®éŸ³' # https://en.wikipedia.org/wiki/Haiku#Examples\n",
    "print('len:', len(my_unicode))\n",
    "print('is text?', isinstance(my_unicode, six.text_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The key fact is that there are a variety of ways to convert Unicode into bytes, and/or bytes into Unicode.** You need to choose a \"codec\" to do the conversion. Conversions are not always possible: given a choice of encoding, some Unicode characters may not be representable (plain ASCII cannot express the letter \"Ã©\") and some byte sequences may not make sense (UTF-8 disallows internal zero bytes).\n",
    "\n",
    "The only codec we are ever going to care about is UTF-8, which is like ASCII but can express almost any Unicode text in a compatible way if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "japanese text encoded as bytes in UTF8 encoding:\n",
      "\n",
      " b'\\xe5\\x8f\\xa4\\xe6\\xb1\\xa0\\xe3\\x82\\x84\\xe8\\x9b\\x99\\xe9\\xa3\\x9b\\xe3\\x81\\xb3\\xe8\\xbe\\xbc\\xe3\\x82\\x80\\xe6\\xb0\\xb4\\xe3\\x81\\xae\\xe9\\x9f\\xb3' \n",
      "\n",
      "len: 33\n",
      "\n",
      "japanese text encoded as bytes in Shift-JIS encoding:\n",
      "\n",
      " b'\\x8c\\xc3\\x92r\\x82\\xe2\\x8a^\\x94\\xf2\\x82\\xd1\\x8d\\x9e\\x82\\xde\\x90\\x85\\x82\\xcc\\x89\\xb9' \n",
      "\n",
      "len: 22\n",
      "\n",
      "could not represent the text in the ASCII encoding: 'ascii' codec can't encode characters in position 0-10: ordinal not in range(128)\n"
     ]
    }
   ],
   "source": [
    "uasb = my_unicode.encode('utf8')\n",
    "assert isinstance(uasb, six.binary_type)\n",
    "print('japanese text encoded as bytes in UTF8 encoding:\\n\\n', repr(uasb), '\\n')\n",
    "print('len:', len(uasb))\n",
    "\n",
    "print()\n",
    "uasb2 = my_unicode.encode('shift-jis')\n",
    "assert isinstance(uasb2, six.binary_type)\n",
    "print('japanese text encoded as bytes in Shift-JIS encoding:\\n\\n', repr(uasb2), '\\n')\n",
    "print('len:', len(uasb2))\n",
    "\n",
    "print()\n",
    "try:\n",
    "    my_unicode.encode('ascii')\n",
    "except Exception as e:\n",
    "    print('could not represent the text in the ASCII encoding:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes converted into Unicode using UTF8 encoding:\n",
      "\n",
      " ðŸ’© \n",
      "\n",
      "len: 1\n",
      "\n",
      "the bytes are not valid Shift-JIS: 'shift_jis' codec can't decode byte 0xf0 in position 0: illegal multibyte sequence\n"
     ]
    }
   ],
   "source": [
    "basu = my_bytes.decode('utf8')\n",
    "assert isinstance(basu, six.text_type)\n",
    "print('bytes converted into Unicode using UTF8 encoding:\\n\\n', basu, '\\n')\n",
    "print('len:', len(basu))\n",
    "\n",
    "print()\n",
    "try:\n",
    "    my_bytes.decode('shift-jis')\n",
    "except Exception as e:\n",
    "    print('the bytes are not valid Shift-JIS:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OK, here's where things get messy.**\n",
    "\n",
    "In Python 2, the \"bytes\" type is good old `str`, and the Unicode type is called `unicode`. If you type a bare string, `'abcd'`, you get bytes/`str`.\n",
    "\n",
    "In Python 3, the \"bytes\" type is named `bytes`, and the Unicode type is called `str`. If you type a bare string you get Unicode/`str`.\n",
    "\n",
    "There are lot of Python APIs that always take `str` in either Python 2 or 3: i.e., in Python 2 they want bytes, and in Python 3 they want Unicode.\n",
    "\n",
    "(This is why I do not recommend using `from __future__ import unicode_literals`, which makes is so that in Python 2 a bare string `'abcd'` becomes of type `unicode`. This makes it challenging to write 2/3-compatible code because it breaks the invariant that `'abcd'` is always an object of type `str`.)\n",
    "\n",
    "So the following invariants hold on both Python 2 and Python 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(b'1234', six.binary_type)\n",
    "assert isinstance(u'1234', six.text_type)\n",
    "assert isinstance('1234', str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/O cares about Unicode vs. bytes\n",
    "\n",
    "As it should! If you use the standard interfaces, you will get `str`, i.e., either bytes or Unicode depending on which Python version is active:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/etc/passwd') as f:\n",
    "    assert isinstance(f.readline(), str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "with io.open('/etc/passwd', 'rt') as f: # 'rt' means 'read mode, text mode'\n",
    "    assert isinstance(f.readline(), six.text_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want binary data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "with io.open('/etc/passwd', 'rb') as f: # 'rb' means 'read mode, binary mode'\n",
    "    assert isinstance(f.readline(), six.binary_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"text mode\" read above automatically chooses a codec to convert the underlying binary file data into text. It will basically always use UTF-8. The `codecs` module provides the tools to do these sorts of conversions of file streams yourself.\n",
    "\n",
    "Analogous patterns hold for writing files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Double extra bonus fun time!!!** Python 2 has a hack to make it so that `print(u'unicode')` automatically chooses a codec and prints something correct.\n",
    "\n",
    "This hack **does not work** if your program's output is redirected into a pipe or a file rather than the terminal. So `./my-unicode-printer.py` works, but `./my-unicode-printer.py >log.txt` doesn't. Weak sauce!\n",
    "\n",
    "My `pwkit` package includes code that can set up your standard output streams to always accept Unicode on both Python 2 and 3: see docs [here](http://pwkit.readthedocs.io/en/latest/foundations/io/#unicode-safety) and [here](http://pwkit.readthedocs.io/en/latest/cli-tools/pwkit-cli-toplevel/#pwkit.cli.unicode_stdio). If you use this approach, you then must ensure that you always ensure that you *only* pass Unicode to `print()`, never bytes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lots of functions return iterators rather than lists\n",
    "\n",
    "This is good for efficiency. To get a consistent API, use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'map'>\n"
     ]
    }
   ],
   "source": [
    "from six.moves import map, range, zip\n",
    "\n",
    "# The type of map's return value will be a \"map object\", not a list, in both 2 and 3:\n",
    "print(type(map(lambda x: x * 2, [1, 2, 3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproducing the old behavior is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6]\n",
      "[2, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "print(list(map(lambda x: x * 2, [1, 2, 3])))\n",
    "print(sorted(map(lambda x: x * 2, [3, 2, 1]))) # no need to listify if you're going to sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also holds true for (e.g.) `dict.keys()`, `dict.items()`, and so on.\n",
    "\n",
    "If you used to use `dict.iterkeys()`, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo\n",
      "bar\n",
      "baz\n"
     ]
    }
   ],
   "source": [
    "import six\n",
    "\n",
    "d = dict(foo=1, bar=2, baz=3)\n",
    "for k in six.iterkeys(d):\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise instead of `xrange`, switch to `range` but put the following at the top of your files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that calling `list()` on a list is a no-op so it's OK to be a bit sloppy about potentially double-listing things in Python 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metaclasses need some extra work\n",
    "\n",
    "Monkey see, monkey do:\n",
    "\n",
    "```python\n",
    "from six import with_metaclass\n",
    "\n",
    "class Form(with_metaclass(FormType, BaseForm)):\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lots of other smaller-bore stuff\n",
    "\n",
    "[Here's a good cheat sheet](http://python-future.org/compatible_idioms.html). Some things that might come up:\n",
    "\n",
    "- `exec` statements\n",
    "- `repr` via backticks\n",
    "- Octal constants\n",
    "- Various package names and locations (`StringIO`, `urllib`, ...)\n",
    "- Custom iterator support\n",
    "- Stringification of classes\n",
    "- `raw_input` calls\n",
    "- All sorts of other fun stuff.\n",
    "\n",
    "Of course, when in doubt, Google it! If you run into any esoteric problems, it's likely that someone has already done so and posted the fix on StackExchange."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: More Bytes/Unicode Gotchas\n",
    "\n",
    "When you start running on Python 3, you'll likely find that some output that your program emits starts looking like `b'hello world'` rather than just `hello world`. Here I try to explain the fundamental cause of what's going on.\n",
    "\n",
    "Basically, the switch from `str`-is-bytes (Python 2) to `str`-is-Unicode (Python 3) has follow-on effects relating to the stringification of both bytes and unicode values.\n",
    "\n",
    "One aspect of the issue relates to `repr`. Here's one way to think about it: in 2/3-compatible code, the `repr` of explictly-typed bytes and Unicode depends on which major version of Python you're running. The `repr` of `str`, however is the same.\n",
    "\n",
    "```python\n",
    "# ONLY TRUE IN PYTHON 2:\n",
    "assert repr(b'123') == \"'123'\"\n",
    "assert repr(u'123') == \"u'123'\"\n",
    "\n",
    "# ONLY TRUE IN PYTHON 3:\n",
    "assert repr(b'123') == \"b'123'\"\n",
    "assert repr(u'123') == \"'123'\"\n",
    "\n",
    "# TRUE IN BOTH:\n",
    "assert repr('123') = '123'\n",
    "```\n",
    "\n",
    "Next, `str` also starts being funky, in an asymmetric way:\n",
    "\n",
    "```python\n",
    "# PYTHON 2:\n",
    "assert str(b'123') = b'123' # generically true: `str(x) = x` if x is bytes\n",
    "\n",
    "# PYTHON 3:\n",
    "assert str(b'123') = repr(b'123') # generically true: `str(x) = repr(x)` if x is bytes\n",
    "```\n",
    "\n",
    "The last line is generally the problem: in Python 3, if you `print` a bytes value, it is stringified, which is equivalent to taking its `repr`, which gives you the value in the  `b''` formatting. Note that if your value was of the `str` type â€” i.e., either bytes or Unicode depending on the Python major version â€” everything would be OK. (In terms of unwanted extra characters from the `repr` operation, that is. From a purist standpoint, calling `print()` with non-Unicode is *always* incorrect, hence [pwkit.cli.unicode_stdio](http://pwkit.readthedocs.io/en/latest/cli-tools/pwkit-cli-toplevel/#pwkit.cli.unicode_stdio). It is *very* challenging to write Python code that is truly correct in these matters, though.)\n",
    "\n",
    "The non-purist solution is to convert from bytes to `str` â€” i.e., a no-op on Python 2, and a decoding operation in Python 3. There is *probably* a nice built-in or `six` way to do this, but one approach is to use a short helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "import six\n",
    "\n",
    "def bytes_to_str(b):\n",
    "    \"\"\"Convert bytes to the str type: a noop on Python 2, and a decode operation on Python 3.\n",
    "    \n",
    "    We hardcode the use of the UTF-8 codec. Depending on the context, it might be better\n",
    "    to use ``sys.getdefaultencoding()``, but sometimes Python chooses ASCII as the default\n",
    "    encoding.\n",
    "    \n",
    "    \"\"\"\n",
    "    if six.PY2: # `six.PY2` is True if are we running on Python 2\n",
    "        return b\n",
    "    return b.decode('utf8')\n",
    "\n",
    "assert bytes_to_str(b'123') == '123'\n",
    "print(bytes_to_str(b'123')) # will reliably give '123'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When writing binary data files, one often wants the inverse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "\n",
    "def str_to_bytes(s):\n",
    "    \"Convert str to the bytes type: a noop on Python 2, and an encode operation on Python 3.\"\n",
    "    \n",
    "    if six.PY2:\n",
    "        return s\n",
    "    return s.encode('utf8')\n",
    "\n",
    "assert str_to_bytes('123') == b'123'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More rarely, you'll have the symmetric problem: a function expects `str`, or auto-stringifies a value, and you have Unicode, leading to potential problems on Python 2. This occurs more rarely because (1) most of us are porting code from 2 â†’ 2/3, not 3 â†’ 2/3, and (2) Python 2 has various hacks to auto-encode Unicode into bytes when needed. However, if this problem does come up, functions analogous to those shown above can help."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
